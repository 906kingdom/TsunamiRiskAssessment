{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ddcc9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "42ca39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_data_path = Path(\"../../data/raw/1/earthquake_data_tsunami.csv\")\n",
    "tsunami_data_path = Path(\"../../data/raw/1/tsunami_dataset.csv\")\n",
    "\n",
    "eq_df = pd.read_csv(eq_data_path)\n",
    "tsunami_df = pd.read_csv(tsunami_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b18564f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION_NAME</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>...</th>\n",
       "      <th>CAUSE</th>\n",
       "      <th>EVENT_VALIDITY</th>\n",
       "      <th>EQ_MAGNITUDE</th>\n",
       "      <th>EQ_DEPTH</th>\n",
       "      <th>TS_INTENSITY</th>\n",
       "      <th>DAMAGE_TOTAL_DESCRIPTION</th>\n",
       "      <th>HOUSES_TOTAL_DESCRIPTION</th>\n",
       "      <th>DEATHS_TOTAL_DESCRIPTION</th>\n",
       "      <th>URL</th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>-330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00</td>\n",
       "      <td>25.000</td>\n",
       "      <td>E. SPORADES ISLANDS, AEGEAN ISLANDS</td>\n",
       "      <td>GREECE</td>\n",
       "      <td>...</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Very Doubtful Tsunami</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ngdc.noaa.gov/hazel/view/hazards/t...</td>\n",
       "      <td>330 B.C. Aegean Sea, Sporades Islands, 40 N 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>481</td>\n",
       "      <td>1764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.45</td>\n",
       "      <td>-2.583</td>\n",
       "      <td>BRISTOL, ENGLAND</td>\n",
       "      <td>UK</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Very Doubtful Tsunami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ngdc.noaa.gov/hazel/view/hazards/t...</td>\n",
       "      <td>Reference #1894, in full: \"On Saturday the 11t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.08</td>\n",
       "      <td>36.250</td>\n",
       "      <td>SAMANDAGI</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td>...</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Questionable Tsunami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ngdc.noaa.gov/hazel/view/hazards/t...</td>\n",
       "      <td>859 (possibly 861), November. Levantian Sea, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186</td>\n",
       "      <td>1580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00</td>\n",
       "      <td>128.000</td>\n",
       "      <td>YELLOW SEA</td>\n",
       "      <td>NORTH KOREA</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Very Doubtful Tsunami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ngdc.noaa.gov/hazel/view/hazards/t...</td>\n",
       "      <td>&lt;P&gt;&lt;blockquote&gt;&lt;i&gt;Reference #414:&lt;/i&gt;&lt;/blockqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.96</td>\n",
       "      <td>26.240</td>\n",
       "      <td>IONIAN COASTS, TROAD</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Questionable Tsunami</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ngdc.noaa.gov/hazel/view/hazards/t...</td>\n",
       "      <td>1300 B.C. Ionian and Aegean Seas. References t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  YEAR  MONTH   DAY  HOUR  MINUTE  LATITUDE  LONGITUDE  \\\n",
       "0   12  -330    NaN   NaN   NaN     NaN     40.00     25.000   \n",
       "1  481  1764    2.0  11.0   NaN     NaN     51.45     -2.583   \n",
       "2   71   859    NaN   NaN   NaN     NaN     36.08     36.250   \n",
       "3  186  1580    1.0   NaN   NaN     NaN     40.00    128.000   \n",
       "4    5 -1300    NaN   NaN   NaN     NaN     39.96     26.240   \n",
       "\n",
       "                         LOCATION_NAME      COUNTRY  ...       CAUSE  \\\n",
       "0  E. SPORADES ISLANDS, AEGEAN ISLANDS       GREECE  ...  Earthquake   \n",
       "1                     BRISTOL, ENGLAND           UK  ...     Unknown   \n",
       "2                            SAMANDAGI       TURKEY  ...  Earthquake   \n",
       "3                           YELLOW SEA  NORTH KOREA  ...     Unknown   \n",
       "4                 IONIAN COASTS, TROAD       TURKEY  ...     Unknown   \n",
       "\n",
       "          EVENT_VALIDITY EQ_MAGNITUDE  EQ_DEPTH  TS_INTENSITY  \\\n",
       "0  Very Doubtful Tsunami          7.0       NaN           NaN   \n",
       "1  Very Doubtful Tsunami          NaN       NaN           NaN   \n",
       "2   Questionable Tsunami          NaN       NaN           3.0   \n",
       "3  Very Doubtful Tsunami          NaN       NaN           1.0   \n",
       "4   Questionable Tsunami          6.0       NaN           5.0   \n",
       "\n",
       "   DAMAGE_TOTAL_DESCRIPTION HOUSES_TOTAL_DESCRIPTION DEATHS_TOTAL_DESCRIPTION  \\\n",
       "0                       NaN                      NaN                      NaN   \n",
       "1                       NaN                      NaN                      NaN   \n",
       "2                       NaN                      NaN                      NaN   \n",
       "3                       NaN                      NaN                      NaN   \n",
       "4                       NaN                      NaN                      NaN   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
       "1  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
       "2  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
       "3  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
       "4  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
       "\n",
       "                                            COMMENTS  \n",
       "0  330 B.C. Aegean Sea, Sporades Islands, 40 N 25...  \n",
       "1  Reference #1894, in full: \"On Saturday the 11t...  \n",
       "2  859 (possibly 861), November. Levantian Sea, N...  \n",
       "3  <P><blockquote><i>Reference #414:</i></blockqu...  \n",
       "4  1300 B.C. Ionian and Aegean Seas. References t...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsunami_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2fa545a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_year = eq_df['Year'].min()\n",
    "min_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6115ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsunami_df = tsunami_df[tsunami_df['YEAR']>2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "cc915077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    }
   ],
   "source": [
    "print(tsunami_df[\"YEAR\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9e28dba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (246, 21)\n",
      "\n",
      "Column Names: ['ID', 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'LATITUDE', 'LONGITUDE', 'LOCATION_NAME', 'COUNTRY', 'REGION', 'CAUSE', 'EVENT_VALIDITY', 'EQ_MAGNITUDE', 'EQ_DEPTH', 'TS_INTENSITY', 'DAMAGE_TOTAL_DESCRIPTION', 'HOUSES_TOTAL_DESCRIPTION', 'DEATHS_TOTAL_DESCRIPTION', 'URL', 'COMMENTS']\n",
      "\n",
      "Missing Values:\n",
      " ID                            0\n",
      "YEAR                          0\n",
      "MONTH                         0\n",
      "DAY                           0\n",
      "HOUR                         20\n",
      "MINUTE                       20\n",
      "LATITUDE                      0\n",
      "LONGITUDE                     0\n",
      "LOCATION_NAME                 0\n",
      "COUNTRY                       0\n",
      "REGION                        0\n",
      "CAUSE                         0\n",
      "EVENT_VALIDITY                0\n",
      "EQ_MAGNITUDE                 35\n",
      "EQ_DEPTH                     34\n",
      "TS_INTENSITY                240\n",
      "DAMAGE_TOTAL_DESCRIPTION    129\n",
      "HOUSES_TOTAL_DESCRIPTION    187\n",
      "DEATHS_TOTAL_DESCRIPTION    176\n",
      "URL                           0\n",
      "COMMENTS                     77\n",
      "dtype: int64\n",
      "\n",
      "First 5 rows:\n",
      "         ID  YEAR  MONTH   DAY  HOUR  MINUTE  LATITUDE  LONGITUDE  \\\n",
      "1214  2395  2002    3.0  26.0   3.0    45.0    23.346    124.090   \n",
      "1226  2404  2001   12.0  18.0   4.0     2.0    23.954    122.734   \n",
      "1227  2434  2004    1.0  28.0  22.0    15.0    -3.120    127.400   \n",
      "1228  2428  2003   10.0  31.0   1.0     6.0    37.812    142.619   \n",
      "1330  2437  2004    9.0   5.0  14.0    57.0    33.184    137.071   \n",
      "\n",
      "                  LOCATION_NAME    COUNTRY  ...       CAUSE    EVENT_VALIDITY  \\\n",
      "1214                      JAPAN      JAPAN  ...  Earthquake  Probable Tsunami   \n",
      "1226                     TAIWAN     TAIWAN  ...  Earthquake  Definite Tsunami   \n",
      "1227               SERAM ISLAND  INDONESIA  ...  Earthquake  Definite Tsunami   \n",
      "1228           E. HONSHU ISLAND      JAPAN  ...  Earthquake  Definite Tsunami   \n",
      "1330  SOUTH COAST HONSHU ISLAND      JAPAN  ...  Earthquake  Definite Tsunami   \n",
      "\n",
      "     EQ_MAGNITUDE  EQ_DEPTH  TS_INTENSITY  DAMAGE_TOTAL_DESCRIPTION  \\\n",
      "1214          6.4      33.0           NaN                       NaN   \n",
      "1226          6.8      14.0           NaN                       NaN   \n",
      "1227          6.7      17.0           NaN                       NaN   \n",
      "1228          7.0      10.0           NaN                       NaN   \n",
      "1330          7.4      10.0           NaN     Limited (<$1 million)   \n",
      "\n",
      "     HOUSES_TOTAL_DESCRIPTION DEATHS_TOTAL_DESCRIPTION  \\\n",
      "1214                      NaN                      NaN   \n",
      "1226                      NaN                      NaN   \n",
      "1227                      NaN                      NaN   \n",
      "1228                      NaN                      NaN   \n",
      "1330                      NaN                      NaN   \n",
      "\n",
      "                                                    URL  \\\n",
      "1214  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
      "1226  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
      "1227  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
      "1228  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
      "1330  https://www.ngdc.noaa.gov/hazel/view/hazards/t...   \n",
      "\n",
      "                                               COMMENTS  \n",
      "1214                                                NaN  \n",
      "1226  Tsunami generated with recorded wave heights o...  \n",
      "1227  A local tsunami was observed at Namlea. (refer...  \n",
      "1228  A small\\r\\ntsunami with a maximum wave height ...  \n",
      "1330  A local tsunami was generated with maximum rec...  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Statistical Summary:\n",
      "                 ID         YEAR       MONTH         DAY        HOUR  \\\n",
      "count   246.000000   246.000000  246.000000  246.000000  226.000000   \n",
      "mean   4722.390244  2011.113821    6.654472   15.898374   11.853982   \n",
      "std    1203.375135     5.162982    3.480341    8.368663    7.134324   \n",
      "min    2373.000000  2001.000000    1.000000    1.000000    0.000000   \n",
      "25%    3598.250000  2007.000000    4.000000   10.000000    5.250000   \n",
      "50%    5449.500000  2011.000000    7.000000   16.000000   12.000000   \n",
      "75%    5636.750000  2015.000000   10.000000   23.000000   18.000000   \n",
      "max    5753.000000  2020.000000   12.000000   31.000000   23.000000   \n",
      "\n",
      "           MINUTE    LATITUDE   LONGITUDE  EQ_MAGNITUDE    EQ_DEPTH  \\\n",
      "count  226.000000  246.000000  246.000000    211.000000  212.000000   \n",
      "mean    30.446903    8.149386   51.062065      7.170616   28.622642   \n",
      "std     16.960590   30.370109  119.925441      0.630864   43.581041   \n",
      "min      0.000000  -60.274000 -179.971000      5.300000    0.000000   \n",
      "25%     16.000000  -17.585250  -71.836750      6.700000   12.000000   \n",
      "50%     31.000000    3.600000  110.326500      7.100000   22.000000   \n",
      "75%     45.750000   37.151250  153.458000      7.600000   32.000000   \n",
      "max     59.000000   71.813000  179.146000      9.100000  563.000000   \n",
      "\n",
      "       TS_INTENSITY  \n",
      "count      6.000000  \n",
      "mean       1.126667  \n",
      "std        3.037833  \n",
      "min       -4.140000  \n",
      "25%        0.645000  \n",
      "50%        1.290000  \n",
      "75%        2.490000  \n",
      "max        5.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Shape:\", tsunami_df.shape)\n",
    "print(\"\\nColumn Names:\", tsunami_df.columns.tolist())\n",
    "print(\"\\nMissing Values:\\n\", tsunami_df.isnull().sum())\n",
    "print(\"\\nFirst 5 rows:\\n\", tsunami_df.head())\n",
    "print(\"\\nStatistical Summary:\\n\", tsunami_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a7d21",
   "metadata": {},
   "source": [
    "### Using year, month, latitude and longitude; we will match and merge two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6bdd747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsunami_locations_and_info = tsunami_df[['YEAR', 'MONTH', 'LATITUDE', 'LONGITUDE', 'EQ_MAGNITUDE', 'EQ_DEPTH']].dropna()\n",
    "# before_tsunami_count = (eq_df['tsunami'] == 1).sum()\n",
    "# print(f\"Tsunami değeri 1 olan deprem sayısı (güncelleme öncesi): {before_tsunami_count}\")\n",
    "# print(f\"Tsunami değeri 0 olan deprem sayısı (güncelleme öncesi): {(eq_df['tsunami'] == 0).sum()}\")\n",
    "# # Her deprem için tsunami kontrolü yap\n",
    "# for idx, row in eq_df.iterrows():\n",
    "\n",
    "#     if eq_df.loc[idx, 'tsunami'] == 0:  # Sadece tsunami değeri 0 olanları kontrol et\n",
    "\n",
    "#         same_time = tsunami_locations_and_info[\n",
    "#             (tsunami_locations_and_info['YEAR'] == row['Year']) & \n",
    "#             (tsunami_locations_and_info['MONTH'] == row['Month'])\n",
    "#         ]\n",
    "        \n",
    "#         if not same_time.empty:\n",
    "#             lat_tolerance = 1.0\n",
    "#             lon_tolerance = 1.0\n",
    "#             magnitude_tolerance = 0.1\n",
    "            \n",
    "#             close_location = same_time[\n",
    "#                 (abs(same_time['LATITUDE'] - row['latitude']) <= lat_tolerance) &\n",
    "#                 (abs(same_time['LONGITUDE'] - row['longitude']) <= lon_tolerance) &\n",
    "#                 (abs(same_time['EQ_MAGNITUDE'] - row['magnitude']) <= magnitude_tolerance)  # Magnitude kriteri eklendi\n",
    "#             ]\n",
    "            \n",
    "#             if not close_location.empty:\n",
    "#                 eq_df.loc[idx, 'tsunami'] = 1\n",
    "#                 #print(f\"Updated tsunami for index {idx}, Year: {row['Year']}, Month: {row['Month']}\")\n",
    "#                 magnitude_eq = row['magnitude']\n",
    "#                 magnitude_ts = close_location.iloc[0]['EQ_MAGNITUDE']\n",
    "#                 depth_eq = row['depth']\n",
    "#                 depth_ts = close_location.iloc[0]['EQ_DEPTH']\n",
    "                \n",
    "# print(f\"Tsunami değeri 1 olan deprem sayısı: {(eq_df['tsunami'] == 1).sum()}\")\n",
    "# print(f\"Tsunami değeri 0 olan deprem sayısı: {(eq_df['tsunami'] == 0).sum()}\")\n",
    "\n",
    "# print(f\"Depremelere yeni atanan tsunami sayısı: {(eq_df['tsunami'] == 1).sum() - before_tsunami_count}\")\n",
    "# print(f\"Eliminated by magnitude/depth offset: {eliminated_by_offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ae63fee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tsunami değeri 1 olan deprem sayısı (güncelleme öncesi): 431\n",
      "Tsunami değeri 0 olan deprem sayısı (güncelleme öncesi): 351\n"
     ]
    }
   ],
   "source": [
    "tsunami_locations_and_info = tsunami_df[['YEAR', 'MONTH', 'LATITUDE', 'LONGITUDE', 'EQ_MAGNITUDE', 'EQ_DEPTH']].dropna()\n",
    "before_tsunami_count = (eq_df['tsunami'] == 1).sum()\n",
    "newly_assigned = []\n",
    "\n",
    "print(f\"Tsunami değeri 1 olan deprem sayısı (güncelleme öncesi): {before_tsunami_count}\")\n",
    "print(f\"Tsunami değeri 0 olan deprem sayısı (güncelleme öncesi): {(eq_df['tsunami'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52536b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tsunami değeri 1 olan deprem sayısı (güncelleme öncesi): 304\n",
      "Tsunami değeri 0 olan deprem sayısı (güncelleme öncesi): 478\n",
      "\n",
      "Tsunami değeri 1 olan deprem sayısı (güncelleme sonrası): 431\n",
      "Tsunami değeri 0 olan deprem sayısı (güncelleme sonrası): 351\n",
      "Depremelere yeni atanan tsunami sayısı: 127\n",
      "\n",
      "=== YENİ ATANAN 127 DEPREMİN DETAYLARI ===\n",
      "\n",
      "Yüksek güvenilirlik (≥80%): 114 deprem\n",
      "Orta güvenilirlik (60-80%): 10 deprem\n",
      "Düşük güvenilirlik (<60%): 3 deprem\n",
      "\n",
      "Ortalama güvenilirlik: 93.7%\n",
      "\n",
      "=== EN İYİ 10 EŞLEŞME ===\n",
      "\n",
      "1. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2015.0/11.0\n",
      "   Konum farkı: Δlat=0.000° (tol=1.5), Δlon=0.000° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.6)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "2. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2012.0/9.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.8)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "3. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2012.0/8.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.8)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "4. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2012.0/8.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.6)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "5. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2012.0/4.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.8)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "6. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2012.0/3.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.6)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "7. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2011.0/7.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.8)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "8. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2011.0/5.0\n",
      "   Konum farkı: Δlat=0.000° (tol=1.5), Δlon=0.000° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.6)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "9. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2011.0/4.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.6)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "10. Eşleşme (Güvenilirlik: 100.0%)\n",
      "   Tarih: 2010.0/12.0\n",
      "   Konum farkı: Δlat=0.000° (tol=2.0), Δlon=0.000° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.6)\n",
      "   Derinlik farkı: Δd=0.0 km (tol=30)\n",
      "\n",
      "=== EN KÖTÜ 10 EŞLEŞME ===\n",
      "\n",
      "1. Eşleşme (Güvenilirlik: 50.9%)\n",
      "   Tarih: 2007.0/9.0\n",
      "   Konum farkı: Δlat=1.813° (tol=2.0), Δlon=0.526° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.50 (tol=0.8)\n",
      "   Derinlik farkı: Δd=1.0 km (tol=30)\n",
      "\n",
      "2. Eşleşme (Güvenilirlik: 53.1%)\n",
      "   Tarih: 2008.0/6.0\n",
      "   Konum farkı: Δlat=1.478° (tol=1.5), Δlon=1.333° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.00 (tol=0.6)\n",
      "   Derinlik farkı: Δd=14.2 km (tol=30)\n",
      "\n",
      "3. Eşleşme (Güvenilirlik: 59.8%)\n",
      "   Tarih: 2011.0/3.0\n",
      "   Konum farkı: Δlat=0.377° (tol=2.0), Δlon=1.748° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.20 (tol=0.8)\n",
      "   Derinlik farkı: Δd=13.4 km (tol=30)\n",
      "\n",
      "4. Eşleşme (Güvenilirlik: 61.1%)\n",
      "   Tarih: 2011.0/8.0\n",
      "   Konum farkı: Δlat=0.003° (tol=1.5), Δlon=0.062° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.50 (tol=0.6)\n",
      "   Derinlik farkı: Δd=7.0 km (tol=30)\n",
      "\n",
      "5. Eşleşme (Güvenilirlik: 63.4%)\n",
      "   Tarih: 2014.0/6.0\n",
      "   Konum farkı: Δlat=0.039° (tol=1.5), Δlon=0.209° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.40 (tol=0.6)\n",
      "   Derinlik farkı: Δd=10.0 km (tol=30)\n",
      "\n",
      "6. Eşleşme (Güvenilirlik: 64.5%)\n",
      "   Tarih: 2016.0/12.0\n",
      "   Konum farkı: Δlat=0.093° (tol=1.5), Δlon=0.182° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.40 (tol=0.6)\n",
      "   Derinlik farkı: Δd=7.7 km (tol=30)\n",
      "\n",
      "7. Eşleşme (Güvenilirlik: 70.2%)\n",
      "   Tarih: 2011.0/2.0\n",
      "   Konum farkı: Δlat=1.094° (tol=1.5), Δlon=0.291° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.10 (tol=0.6)\n",
      "   Derinlik farkı: Δd=7.0 km (tol=30)\n",
      "\n",
      "8. Eşleşme (Güvenilirlik: 72.1%)\n",
      "   Tarih: 2013.0/2.0\n",
      "   Konum farkı: Δlat=0.255° (tol=2.0), Δlon=1.136° (tol=2.0)\n",
      "   Büyüklük farkı: ΔM=0.10 (tol=0.6)\n",
      "   Derinlik farkı: Δd=11.0 km (tol=30)\n",
      "\n",
      "9. Eşleşme (Güvenilirlik: 76.1%)\n",
      "   Tarih: 2005.0/4.0\n",
      "   Konum farkı: Δlat=0.070° (tol=1.5), Δlon=0.172° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.20 (tol=0.6)\n",
      "   Derinlik farkı: Δd=11.0 km (tol=30)\n",
      "\n",
      "10. Eşleşme (Güvenilirlik: 76.8%)\n",
      "   Tarih: 2014.0/4.0\n",
      "   Konum farkı: Δlat=0.346° (tol=1.5), Δlon=0.238° (tol=1.5)\n",
      "   Büyüklük farkı: ΔM=0.20 (tol=0.6)\n",
      "   Derinlik farkı: Δd=3.1 km (tol=30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Adaptive tolerances based on research\n",
    "def get_adaptive_tolerances(magnitude, depth):\n",
    "    \"\"\"\n",
    "    Returns adaptive tolerances based on magnitude and depth.\n",
    "    Research shows larger events and deeper events have greater location/magnitude uncertainties.\n",
    "    \"\"\"\n",
    "    # Latitude/Longitude tolerance (degrees)\n",
    "    # Historical events and larger magnitudes have greater location uncertainty\n",
    "    if magnitude >= 7.0:\n",
    "        lat_tol = 2.0  # ~220 km at equator\n",
    "        lon_tol = 2.0\n",
    "    elif magnitude >= 6.0:\n",
    "        lat_tol = 1.5  # ~165 km\n",
    "        lon_tol = 1.5\n",
    "    else:\n",
    "        lat_tol = 1.0  # ~110 km\n",
    "        lon_tol = 1.0\n",
    "    \n",
    "    # Magnitude tolerance\n",
    "    # Research shows 0.3-0.6 typical, up to 1.0+ for great earthquakes\n",
    "    if magnitude >= 7.5:\n",
    "        mag_tol = 0.8  # Great earthquakes have larger discrepancies\n",
    "    elif magnitude >= 6.5:\n",
    "        mag_tol = 0.6\n",
    "    else:\n",
    "        mag_tol = 0.4  # Smaller events more consistent\n",
    "    \n",
    "    # Depth tolerance (km)\n",
    "    # Deep earthquakes have much larger depth uncertainties\n",
    "    if depth >= 300:\n",
    "        depth_tol = 100  # Very deep events\n",
    "    elif depth >= 100:\n",
    "        depth_tol = 75   # Intermediate depth\n",
    "    elif depth >= 50:\n",
    "        depth_tol = 50\n",
    "    else:\n",
    "        depth_tol = 30   # Shallow events more precise\n",
    "    \n",
    "    return lat_tol, lon_tol, mag_tol, depth_tol\n",
    "\n",
    "# Confidence scoring system\n",
    "def calculate_match_confidence(lat_diff, lon_diff, mag_diff, depth_diff, \n",
    "                                lat_tol, lon_tol, mag_tol, depth_tol):\n",
    "    \"\"\"\n",
    "    Calculate a confidence score for the match (0-100%)\n",
    "    \"\"\"\n",
    "    # Normalized differences (0 = perfect match, 1 = at tolerance limit)\n",
    "    lat_norm = min(lat_diff / lat_tol, 1.0)\n",
    "    lon_norm = min(lon_diff / lon_tol, 1.0)\n",
    "    mag_norm = min(mag_diff / mag_tol, 1.0)\n",
    "    depth_norm = min(depth_diff / depth_tol, 1.0) if depth_tol > 0 else 0\n",
    "    \n",
    "    # Weighted confidence (location 40%, magnitude 40%, depth 20%)\n",
    "    # Research shows magnitude and location are most critical for tsunami matching\n",
    "    confidence = 100 * (1 - (0.2 * lat_norm + 0.2 * lon_norm + \n",
    "                             0.4 * mag_norm + 0.2 * depth_norm))\n",
    "    return max(0, confidence)\n",
    "\n",
    "# Time window tolerance - allow ±1 month for historical data inaccuracies\n",
    "def check_time_match(eq_year, eq_month, ts_year, ts_month):\n",
    "    \"\"\"\n",
    "    Check if times match within tolerance.\n",
    "    Historical catalogs may have month discrepancies due to calendar conversions.\n",
    "    \"\"\"\n",
    "    if eq_year != ts_year:\n",
    "        return False\n",
    "    # Allow exact month or ±1 month difference\n",
    "    month_diff = abs(eq_month - ts_month)\n",
    "    return month_diff <= 1\n",
    "\n",
    "# Enhanced matching algorithm\n",
    "for idx, row in eq_df.iterrows():\n",
    "    if eq_df.loc[idx, 'tsunami'] == 0:\n",
    "        # First filter by time (with tolerance)\n",
    "        same_time = tsunami_locations_and_info[\n",
    "            tsunami_locations_and_info.apply(\n",
    "                lambda x: check_time_match(row['Year'], row['Month'], \n",
    "                                          x['YEAR'], x['MONTH']), \n",
    "                axis=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if not same_time.empty:\n",
    "            best_match = None\n",
    "            best_confidence = 0\n",
    "            \n",
    "            for _, ts_event in same_time.iterrows():\n",
    "                # Get adaptive tolerances\n",
    "                avg_magnitude = (row['magnitude'] + ts_event['EQ_MAGNITUDE']) / 2\n",
    "                avg_depth = (row['depth'] + ts_event['EQ_DEPTH']) / 2\n",
    "                lat_tol, lon_tol, mag_tol, depth_tol = get_adaptive_tolerances(\n",
    "                    avg_magnitude, avg_depth\n",
    "                )\n",
    "                \n",
    "                # Calculate differences\n",
    "                lat_diff = abs(ts_event['LATITUDE'] - row['latitude'])\n",
    "                lon_diff = abs(ts_event['LONGITUDE'] - row['longitude'])\n",
    "                mag_diff = abs(ts_event['EQ_MAGNITUDE'] - row['magnitude'])\n",
    "                depth_diff = abs(ts_event['EQ_DEPTH'] - row['depth'])\n",
    "                \n",
    "                # Check if within tolerances\n",
    "                if (lat_diff <= lat_tol and lon_diff <= lon_tol and \n",
    "                    mag_diff <= mag_tol and depth_diff <= depth_tol):\n",
    "                    \n",
    "                    # Calculate confidence\n",
    "                    confidence = calculate_match_confidence(\n",
    "                        lat_diff, lon_diff, mag_diff, depth_diff,\n",
    "                        lat_tol, lon_tol, mag_tol, depth_tol\n",
    "                    )\n",
    "                    \n",
    "                    # Keep best match\n",
    "                    if confidence > best_confidence:\n",
    "                        best_confidence = confidence\n",
    "                        best_match = {\n",
    "                            'ts_event': ts_event,\n",
    "                            'lat_diff': lat_diff,\n",
    "                            'lon_diff': lon_diff,\n",
    "                            'mag_diff': mag_diff,\n",
    "                            'depth_diff': depth_diff,\n",
    "                            'confidence': confidence,\n",
    "                            'tolerances': (lat_tol, lon_tol, mag_tol, depth_tol)\n",
    "                        }\n",
    "            \n",
    "            # Assign tsunami if good match found (threshold: 50% confidence)\n",
    "            if best_match and best_confidence >= 50:\n",
    "                eq_df.loc[idx, 'tsunami'] = 1\n",
    "                \n",
    "                ts = best_match['ts_event']\n",
    "                newly_assigned.append({\n",
    "                    'index': idx,\n",
    "                    'year': row['Year'],\n",
    "                    'month': row['Month'],\n",
    "                    'eq_lat': row['latitude'],\n",
    "                    'eq_lon': row['longitude'],\n",
    "                    'eq_magnitude': row['magnitude'],\n",
    "                    'eq_depth': row['depth'],\n",
    "                    'ts_lat': ts['LATITUDE'],\n",
    "                    'ts_lon': ts['LONGITUDE'],\n",
    "                    'ts_magnitude': ts['EQ_MAGNITUDE'],\n",
    "                    'ts_depth': ts['EQ_DEPTH'],\n",
    "                    'lat_diff': best_match['lat_diff'],\n",
    "                    'lon_diff': best_match['lon_diff'],\n",
    "                    'mag_diff': best_match['mag_diff'],\n",
    "                    'depth_diff': best_match['depth_diff'],\n",
    "                    'confidence': best_match['confidence'],\n",
    "                    'lat_tol': best_match['tolerances'][0],\n",
    "                    'lon_tol': best_match['tolerances'][1],\n",
    "                    'mag_tol': best_match['tolerances'][2],\n",
    "                    'depth_tol': best_match['tolerances'][3]\n",
    "                })\n",
    "\n",
    "after_tsunami_count = (eq_df['tsunami'] == 1).sum()\n",
    "\n",
    "print(f\"\\nTsunami değeri 1 olan deprem sayısı (güncelleme sonrası): {after_tsunami_count}\")\n",
    "print(f\"Tsunami değeri 0 olan deprem sayısı (güncelleme sonrası): {(eq_df['tsunami'] == 0).sum()}\")\n",
    "print(f\"Depremelere yeni atanan tsunami sayısı: {after_tsunami_count - before_tsunami_count}\")\n",
    "\n",
    "# Enhanced reporting with confidence levels\n",
    "if newly_assigned:\n",
    "    print(f\"\\n=== YENİ ATANAN {len(newly_assigned)} DEPREMİN DETAYLARI ===\")\n",
    "    \n",
    "    high_conf = [eq for eq in newly_assigned if eq['confidence'] >= 80]\n",
    "    medium_conf = [eq for eq in newly_assigned if 60 <= eq['confidence'] < 80]\n",
    "    low_conf = [eq for eq in newly_assigned if eq['confidence'] < 60]\n",
    "    \n",
    "    print(f\"\\nYüksek güvenilirlik (≥80%): {len(high_conf)} deprem\")\n",
    "    print(f\"Orta güvenilirlik (60-80%): {len(medium_conf)} deprem\")\n",
    "    print(f\"Düşük güvenilirlik (<60%): {len(low_conf)} deprem\")\n",
    "    \n",
    "    print(f\"\\nOrtalama güvenilirlik: {np.mean([eq['confidence'] for eq in newly_assigned]):.1f}%\")\n",
    "    \n",
    "    # Show top 10 matches\n",
    "    print(\"\\n=== EN İYİ 10 EŞLEŞME ===\")\n",
    "    sorted_matches = sorted(newly_assigned, key=lambda x: x['confidence'], reverse=True)[:10]\n",
    "    for i, eq in enumerate(sorted_matches, 1):\n",
    "        print(f\"\\n{i}. Eşleşme (Güvenilirlik: {eq['confidence']:.1f}%)\")\n",
    "        print(f\"   Tarih: {eq['year']}/{eq['month']}\")\n",
    "        print(f\"   Konum farkı: Δlat={eq['lat_diff']:.3f}° (tol={eq['lat_tol']}), \"\n",
    "              f\"Δlon={eq['lon_diff']:.3f}° (tol={eq['lon_tol']})\")\n",
    "        print(f\"   Büyüklük farkı: ΔM={eq['mag_diff']:.2f} (tol={eq['mag_tol']})\")\n",
    "        print(f\"   Derinlik farkı: Δd={eq['depth_diff']:.1f} km (tol={eq['depth_tol']})\")\n",
    "\n",
    "    # Show bottom 10 matches\n",
    "    print(\"\\n=== EN KÖTÜ 10 EŞLEŞME ===\")\n",
    "    sorted_matches = sorted(newly_assigned, key=lambda x: x['confidence'])[:10]\n",
    "    for i, eq in enumerate(sorted_matches, 1):\n",
    "        print(f\"\\n{i}. Eşleşme (Güvenilirlik: {eq['confidence']:.1f}%)\")\n",
    "        print(f\"   Tarih: {eq['year']}/{eq['month']}\")\n",
    "        print(f\"   Konum farkı: Δlat={eq['lat_diff']:.3f}° (tol={eq['lat_tol']}), \"\n",
    "              f\"Δlon={eq['lon_diff']:.3f}° (tol={eq['lon_tol']})\")\n",
    "        print(f\"   Büyüklük farkı: ΔM={eq['mag_diff']:.2f} (tol={eq['mag_tol']})\")\n",
    "        print(f\"   Derinlik farkı: Δd={eq['depth_diff']:.1f} km (tol={eq['depth_tol']})\")\n",
    "\n",
    "    print(len(newly_assigned['confidence']>85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c58ef0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "print(len([eq for eq in newly_assigned if eq['confidence'] > np.mean([eq['confidence'] for eq in newly_assigned])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769fc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
