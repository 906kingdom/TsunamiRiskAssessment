{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Optimization for Top 4 Models\n",
        "\n",
        "Based on baseline test F2 scores from model_results.csv, we selected the top 4 models for hyperparameter optimization:\n",
        "1. **TabPFN**: 0.7685 (F2 score)\n",
        "2. **CatBoost**: 0.7152 (F2 score)\n",
        "3. **Logistic Regression**: 0.7129 (F2 score)\n",
        "4. **LightGBM**: 0.6859 (F2 score)\n",
        "\n",
        "\n",
        "This notebook performs hyperparameter optimization for these three models using F2 score as the primary metric (emphasizes recall - critical for tsunami detection).\n",
        "\n",
        "**Note**: After optimization, TabPFN achieved the best F2 score (0.7733), followed by LightGBM (0.7609), CatBoost (0.7477) and Logistic Regression (0.7215). See the Summary section for detailed results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_validate, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    make_scorer, accuracy_score, precision_score, recall_score, \n",
        "    f1_score, fbeta_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "import json\n",
        "from tabpfn import TabPFNRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "data_path = Path(\"../data/processed/earthquake_data_tsunami_scaled.csv\")\n",
        "data_df = pd.read_csv(data_path)\n",
        "\n",
        "# Prepare features (same as in previous notebooks)\n",
        "features_to_exclude = ['tsunami', 'Year', 'Month','month_number','dmin','nst','longitude','latitude']\n",
        "X = data_df.drop(columns=[col for col in features_to_exclude if col in data_df.columns])\n",
        "y = data_df['tsunami']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.5454545454545454"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# F2 scorer (emphasizes recall - critical for tsunami detection)\n",
        "f2_scorer = make_scorer(fbeta_score, beta=2.0, zero_division=0)\n",
        "\n",
        "# Calculate class weight ratio\n",
        "class_weight_ratio = (y == 0).sum() / (y == 1).sum()\n",
        "float(class_weight_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: CatBoost Hyperparameter Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost parameter grid:\n",
            "  depth: [3, 4, 5, 6]\n",
            "  learning_rate: [0.01, 0.05, 0.1, 0.15]\n",
            "  iterations: [100, 200, 300]\n",
            "  l2_leaf_reg: [1, 3, 5, 7]\n",
            "  subsample: [0.6, 0.7, 0.8, 0.9]\n",
            "  min_data_in_leaf: [1, 3, 5, 10]\n",
            "  random_strength: [0.5, 1.0, 2.0]\n"
          ]
        }
      ],
      "source": [
        "# CatBoost parameter grid\n",
        "catboost_param_grid = {\n",
        "    'depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
        "    'iterations': [100, 200, 300],\n",
        "    'l2_leaf_reg': [1, 3, 5, 7],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
        "    'min_data_in_leaf': [1, 3, 5, 10],\n",
        "    'random_strength': [0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "print(\"CatBoost parameter grid:\")\n",
        "for key, value in catboost_param_grid.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "CatBoost Best Parameters:\n",
            "{'subsample': 0.8, 'random_strength': 0.5, 'min_data_in_leaf': 3, 'learning_rate': 0.05, 'l2_leaf_reg': 3, 'iterations': 100, 'depth': 4}\n",
            "\n",
            "CatBoost Best F2 Score: 0.7477\n"
          ]
        }
      ],
      "source": [
        "# CatBoost base model\n",
        "catboost_base = CatBoostClassifier(\n",
        "    class_weights=[1, class_weight_ratio],\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=False,\n",
        "    allow_writing_files=False,\n",
        "    loss_function='Logloss'\n",
        ")\n",
        "\n",
        "# Randomized search (faster than grid search for large parameter spaces)\n",
        "catboost_search = RandomizedSearchCV(\n",
        "    estimator=catboost_base,\n",
        "    param_distributions=catboost_param_grid,\n",
        "    n_iter=50,  # Number of parameter settings sampled\n",
        "    cv=skf,\n",
        "    scoring=f2_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "catboost_search.fit(X, y)\n",
        "\n",
        "print(\"\\nCatBoost Best Parameters:\")\n",
        "print(catboost_search.best_params_)\n",
        "print(f\"\\nCatBoost Best F2 Score: {catboost_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost Optimized Results:\n",
            "  Test Accuracy: 0.8300\n",
            "  Test Precision: 0.5839\n",
            "  Test Recall: 0.8054\n",
            "  Test F1: 0.6760\n",
            "  Test F2: 0.7477\n",
            "  Test ROC-AUC: 0.8212\n",
            "  False Negative Rate: 19.48%\n",
            "  Train/Test Gap (Accuracy): 0.0293\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best CatBoost model with full metrics\n",
        "scoring_dict = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, zero_division=0),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'f2': f2_scorer,\n",
        "    'roc_auc': make_scorer(roc_auc_score)\n",
        "}\n",
        "\n",
        "catboost_best = catboost_search.best_estimator_\n",
        "catboost_cv_results = cross_validate(\n",
        "    catboost_best, X, y,\n",
        "    cv=skf,\n",
        "    scoring=scoring_dict,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "catboost_y_pred = cross_val_predict(catboost_best, X, y, cv=skf, n_jobs=-1)\n",
        "catboost_cm = confusion_matrix(y, catboost_y_pred)\n",
        "catboost_fn_rate = catboost_cm[1, 0] / catboost_cm[1, :].sum() * 100\n",
        "\n",
        "print(\"CatBoost Optimized Results:\")\n",
        "print(f\"  Test Accuracy: {catboost_cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Test Precision: {catboost_cv_results['test_precision'].mean():.4f}\")\n",
        "print(f\"  Test Recall: {catboost_cv_results['test_recall'].mean():.4f}\")\n",
        "print(f\"  Test F1: {catboost_cv_results['test_f1'].mean():.4f}\")\n",
        "print(f\"  Test F2: {catboost_cv_results['test_f2'].mean():.4f}\")\n",
        "print(f\"  Test ROC-AUC: {catboost_cv_results['test_roc_auc'].mean():.4f}\")\n",
        "print(f\"  False Negative Rate: {catboost_fn_rate:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {catboost_cv_results['train_accuracy'].mean() - catboost_cv_results['test_accuracy'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Logistic Regression Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression parameter grid:\n",
            "  classifier__C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
            "  classifier__penalty: ['l1', 'l2', 'elasticnet']\n",
            "  classifier__solver: ['lbfgs', 'liblinear', 'saga']\n",
            "  classifier__max_iter: [1000, 2000, 5000]\n",
            "  classifier__class_weight: ['balanced', {0: 1, 1: np.float64(3.5454545454545454)}, None]\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression parameter grid\n",
        "lr_param_grid = {\n",
        "    'classifier__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'classifier__solver': ['lbfgs', 'liblinear', 'saga'],\n",
        "    'classifier__max_iter': [1000, 2000, 5000],\n",
        "    'classifier__class_weight': ['balanced', {0: 1, 1: class_weight_ratio}, None]\n",
        "}\n",
        "\n",
        "print(\"Logistic Regression parameter grid:\")\n",
        "for key, value in lr_param_grid.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "Logistic Regression Best Parameters:\n",
            "{'classifier__solver': 'saga', 'classifier__penalty': 'l1', 'classifier__max_iter': 1000, 'classifier__class_weight': 'balanced', 'classifier__C': 0.1}\n",
            "\n",
            "Logistic Regression Best F2 Score: 0.7215\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression pipeline with StandardScaler\n",
        "lr_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "\n",
        "lr_search = RandomizedSearchCV(\n",
        "    estimator=lr_pipeline,\n",
        "    param_distributions={\n",
        "        'classifier__C': lr_param_grid['classifier__C'],\n",
        "        'classifier__penalty': ['l1', 'l2'],  # Exclude elasticnet for simplicity\n",
        "        'classifier__solver': ['liblinear', 'saga'],  # Both support l1 and l2\n",
        "        'classifier__max_iter': lr_param_grid['classifier__max_iter'],\n",
        "        'classifier__class_weight': lr_param_grid['classifier__class_weight']\n",
        "    },\n",
        "    n_iter=50,  # Sample 50 parameter combinations\n",
        "    cv=skf,\n",
        "    scoring=f2_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1,\n",
        "    error_score='raise'\n",
        ")\n",
        "\n",
        "lr_search.fit(X, y)\n",
        "\n",
        "print(\"\\nLogistic Regression Best Parameters:\")\n",
        "print(lr_search.best_params_)\n",
        "print(f\"\\nLogistic Regression Best F2 Score: {lr_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Optimized Results:\n",
            "  Test Accuracy: 0.7729\n",
            "  Test Precision: 0.4933\n",
            "  Test Recall: 0.8187\n",
            "  Test F1: 0.6139\n",
            "  Test F2: 0.7215\n",
            "  Test ROC-AUC: 0.7894\n",
            "  False Negative Rate: 18.18%\n",
            "  Train/Test Gap (Accuracy): 0.0039\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best Logistic Regression model\n",
        "lr_best = lr_search.best_estimator_\n",
        "lr_cv_results = cross_validate(\n",
        "    lr_best, X, y,\n",
        "    cv=skf,\n",
        "    scoring=scoring_dict,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_y_pred = cross_val_predict(lr_best, X, y, cv=skf, n_jobs=-1)\n",
        "lr_cm = confusion_matrix(y, lr_y_pred)\n",
        "lr_fn_rate = lr_cm[1, 0] / lr_cm[1, :].sum() * 100\n",
        "\n",
        "print(\"Logistic Regression Optimized Results:\")\n",
        "print(f\"  Test Accuracy: {lr_cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Test Precision: {lr_cv_results['test_precision'].mean():.4f}\")\n",
        "print(f\"  Test Recall: {lr_cv_results['test_recall'].mean():.4f}\")\n",
        "print(f\"  Test F1: {lr_cv_results['test_f1'].mean():.4f}\")\n",
        "print(f\"  Test F2: {lr_cv_results['test_f2'].mean():.4f}\")\n",
        "print(f\"  Test ROC-AUC: {lr_cv_results['test_roc_auc'].mean():.4f}\")\n",
        "print(f\"  False Negative Rate: {lr_fn_rate:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {lr_cv_results['train_accuracy'].mean() - lr_cv_results['test_accuracy'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 3: LightGBM Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM parameter grid:\n",
            "  max_depth: [3, 4, 5, 6, 7]\n",
            "  learning_rate: [0.01, 0.05, 0.1, 0.15]\n",
            "  n_estimators: [100, 200, 300, 400]\n",
            "  num_leaves: [15, 31, 50, 70]\n",
            "  subsample: [0.6, 0.7, 0.8, 0.9]\n",
            "  colsample_bytree: [0.6, 0.7, 0.8, 0.9]\n",
            "  min_child_samples: [5, 10, 20, 30]\n",
            "  reg_alpha: [0, 0.1, 0.5, 1.0]\n",
            "  reg_lambda: [0, 0.1, 0.5, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# LightGBM parameter grid\n",
        "lgbm_param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'num_leaves': [15, 31, 50, 70],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
        "    'min_child_samples': [5, 10, 20, 30],\n",
        "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
        "    'reg_lambda': [0, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "print(\"LightGBM parameter grid:\")\n",
        "for key, value in lgbm_param_grid.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "LightGBM Best Parameters:\n",
            "{'subsample': 0.7, 'reg_lambda': 0.1, 'reg_alpha': 0.5, 'num_leaves': 15, 'n_estimators': 400, 'min_child_samples': 20, 'max_depth': 4, 'learning_rate': 0.01, 'colsample_bytree': 0.9}\n",
            "\n",
            "LightGBM Best F2 Score: 0.7609\n"
          ]
        }
      ],
      "source": [
        "# LightGBM base model\n",
        "lgbm_base = lgb.LGBMClassifier(\n",
        "    scale_pos_weight=class_weight_ratio,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbosity=-1,\n",
        "    force_col_wise=True,\n",
        "    objective='binary',\n",
        "    metric='binary_logloss'\n",
        ")\n",
        "\n",
        "# Randomized search\n",
        "lgbm_search = RandomizedSearchCV(\n",
        "    estimator=lgbm_base,\n",
        "    param_distributions=lgbm_param_grid,\n",
        "    n_iter=50,  # Number of parameter settings sampled\n",
        "    cv=skf,\n",
        "    scoring=f2_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lgbm_search.fit(X, y)\n",
        "\n",
        "print(\"\\nLightGBM Best Parameters:\")\n",
        "print(lgbm_search.best_params_)\n",
        "print(f\"\\nLightGBM Best F2 Score: {lgbm_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Optimized Results:\n",
            "  Test Accuracy: 0.8300\n",
            "  Test Precision: 0.5828\n",
            "  Test Recall: 0.8245\n",
            "  Test F1: 0.6823\n",
            "  Test F2: 0.7609\n",
            "  Test ROC-AUC: 0.8280\n",
            "  False Negative Rate: 17.53%\n",
            "  Train/Test Gap (Accuracy): 0.0514\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best LightGBM model\n",
        "lgbm_best = lgbm_search.best_estimator_\n",
        "lgbm_cv_results = cross_validate(\n",
        "    lgbm_best, X, y,\n",
        "    cv=skf,\n",
        "    scoring=scoring_dict,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_y_pred = cross_val_predict(lgbm_best, X, y, cv=skf, n_jobs=-1)\n",
        "lgbm_cm = confusion_matrix(y, lgbm_y_pred)\n",
        "lgbm_fn_rate = lgbm_cm[1, 0] / lgbm_cm[1, :].sum() * 100\n",
        "\n",
        "print(\"LightGBM Optimized Results:\")\n",
        "print(f\"  Test Accuracy: {lgbm_cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Test Precision: {lgbm_cv_results['test_precision'].mean():.4f}\")\n",
        "print(f\"  Test Recall: {lgbm_cv_results['test_recall'].mean():.4f}\")\n",
        "print(f\"  Test F1: {lgbm_cv_results['test_f1'].mean():.4f}\")\n",
        "print(f\"  Test F2: {lgbm_cv_results['test_f2'].mean():.4f}\")\n",
        "print(f\"  Test ROC-AUC: {lgbm_cv_results['test_roc_auc'].mean():.4f}\")\n",
        "print(f\"  False Negative Rate: {lgbm_fn_rate:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {lgbm_cv_results['train_accuracy'].mean() - lgbm_cv_results['test_accuracy'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 4: TabPFN Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tabpfn import TabPFNClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "if 'best_threshold' not in locals():\n",
        "    best_threshold = 0.2 \n",
        "   \n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = TabPFNClassifier(device=\"cuda\") \n",
        "\n",
        "train_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'f2': [], 'roc_auc': []}\n",
        "test_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'f2': [], 'roc_auc': [], 'fn_rate': []}\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
        "    \n",
        "    model.fit(X_train_cv, y_train_cv)\n",
        "    \n",
        "    y_train_proba = model.predict_proba(X_train_cv)[:, 1]\n",
        "    y_test_proba = model.predict_proba(X_test_cv)[:, 1]\n",
        "    \n",
        "    y_train_pred = (y_train_proba >= best_threshold).astype(int)\n",
        "    y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
        "    \n",
        "    train_metrics['accuracy'].append(accuracy_score(y_train_cv, y_train_pred))\n",
        "    train_metrics['roc_auc'].append(roc_auc_score(y_train_cv, y_train_proba)) # AUC olasılıkla hesaplanır\n",
        "    \n",
        "    test_metrics['accuracy'].append(accuracy_score(y_test_cv, y_test_pred))\n",
        "    test_metrics['precision'].append(precision_score(y_test_cv, y_test_pred, zero_division=0))\n",
        "    test_metrics['recall'].append(recall_score(y_test_cv, y_test_pred, zero_division=0))\n",
        "    test_metrics['f1'].append(f1_score(y_test_cv, y_test_pred, zero_division=0))\n",
        "    test_metrics['f2'].append(fbeta_score(y_test_cv, y_test_pred, beta=2, zero_division=0))\n",
        "    test_metrics['roc_auc'].append(roc_auc_score(y_test_cv, y_test_proba))\n",
        "    \n",
        "    cm = confusion_matrix(y_test_cv, y_test_pred)\n",
        "    if cm[1, :].sum() > 0:\n",
        "        fn_rate = cm[1, 0] / cm[1, :].sum() * 100\n",
        "    else:\n",
        "        fn_rate = 0.0\n",
        "    test_metrics['fn_rate'].append(fn_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TabPFN (Optimized Threshold) Results:\n",
            "  Test Accuracy: 0.7286\n",
            "  Test Precision: 0.4464\n",
            "  Test Recall: 0.9484\n",
            "  Test F1: 0.6063\n",
            "  Test F2: 0.7733\n",
            "  Test ROC-AUC: 0.9034\n",
            "  False Negative Rate: 5.16%\n",
            "  Train/Test Gap (Accuracy): 0.0318\n"
          ]
        }
      ],
      "source": [
        "final_results = {\n",
        "    'Test Accuracy': np.mean(test_metrics['accuracy']),\n",
        "    'Test Precision': np.mean(test_metrics['precision']),\n",
        "    'Test Recall': np.mean(test_metrics['recall']),\n",
        "    'Test F1': np.mean(test_metrics['f1']),\n",
        "    'Test F2': np.mean(test_metrics['f2']),\n",
        "    'Test ROC-AUC': np.mean(test_metrics['roc_auc']),\n",
        "    'False Negative Rate': np.mean(test_metrics['fn_rate']),\n",
        "    'Train Accuracy': np.mean(train_metrics['accuracy']),\n",
        "    'Train ROC-AUC': np.mean(train_metrics['roc_auc'])\n",
        "}\n",
        "tab_pfn_best_params_ = {'threshold': float(best_threshold)}\n",
        "print(\"\\nTabPFN (Optimized Threshold) Results:\")\n",
        "print(f\"  Test Accuracy: {final_results['Test Accuracy']:.4f}\")\n",
        "print(f\"  Test Precision: {final_results['Test Precision']:.4f}\")\n",
        "print(f\"  Test Recall: {final_results['Test Recall']:.4f}\")\n",
        "print(f\"  Test F1: {final_results['Test F1']:.4f}\")\n",
        "print(f\"  Test F2: {final_results['Test F2']:.4f}\")\n",
        "print(f\"  Test ROC-AUC: {final_results['Test ROC-AUC']:.4f}\")\n",
        "print(f\"  False Negative Rate: {final_results['False Negative Rate']:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {final_results['Train Accuracy'] - final_results['Test Accuracy']:.4f}\")\n",
        "\n",
        "tabpfn_cv_results = {\n",
        "    'test_accuracy': np.array(test_metrics['accuracy']),\n",
        "    'test_precision': np.array(test_metrics['precision']),\n",
        "    'test_recall': np.array(test_metrics['recall']),\n",
        "    'test_f1': np.array(test_metrics['f1']),\n",
        "    'test_f2': np.array(test_metrics['f2']),\n",
        "    'test_roc_auc': np.array(test_metrics['roc_auc']),\n",
        "    'train_accuracy': np.array(train_metrics['accuracy']),\n",
        "    'train_precision': np.array(train_metrics['precision']),\n",
        "    'train_recall': np.array(train_metrics['recall']),\n",
        "    'train_f1': np.array(train_metrics['f1']),\n",
        "    'train_f2': np.array(train_metrics['f2']),\n",
        "    'train_roc_auc': np.array(train_metrics['roc_auc']),\n",
        "    'train_test_gap_accuracy': np.array(train_metrics['accuracy']).mean() - np.array(test_metrics['accuracy']).mean(),\n",
        "    'false_negative_rate': np.array(test_metrics['fn_rate']).mean(),\n",
        "    'false_negative_percentage': (np.array(test_metrics['fn_rate']).mean() / 100) * (y == 1).sum() / len(y) * 100,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of Optimized Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPARISON OF OPTIMIZED MODELS\n",
            "================================================================================\n",
            "                          Model  Test Accuracy  Test Precision  Test Recall  Test F1  Test F2  Test ROC-AUC  False Negative Rate (%)  Train/Test Gap (Accuracy)\n",
            "           CatBoost (Optimized)         0.8300          0.5839       0.8054   0.6760   0.7477        0.8212                  19.4805                     0.0293\n",
            "Logistic Regression (Optimized)         0.7729          0.4933       0.8187   0.6139   0.7215        0.7894                  18.1818                     0.0039\n",
            "           LightGBM (Optimized)         0.8300          0.5828       0.8245   0.6823   0.7609        0.8280                  17.5325                     0.0514\n",
            "             TabPFN (Optimized)         0.7286          0.4464       0.9484   0.6063   0.7733        0.9034                   5.1613                     0.0318\n",
            "\n",
            "================================================================================\n",
            "MODELS RANKED BY TEST F2 SCORE (Primary Metric)\n",
            "================================================================================\n",
            "                          Model  Test Accuracy  Test Precision  Test Recall  Test F1  Test F2  Test ROC-AUC  False Negative Rate (%)  Train/Test Gap (Accuracy)\n",
            "             TabPFN (Optimized)         0.7286          0.4464       0.9484   0.6063   0.7733        0.9034                   5.1613                     0.0318\n",
            "           LightGBM (Optimized)         0.8300          0.5828       0.8245   0.6823   0.7609        0.8280                  17.5325                     0.0514\n",
            "           CatBoost (Optimized)         0.8300          0.5839       0.8054   0.6760   0.7477        0.8212                  19.4805                     0.0293\n",
            "Logistic Regression (Optimized)         0.7729          0.4933       0.8187   0.6139   0.7215        0.7894                  18.1818                     0.0039\n"
          ]
        }
      ],
      "source": [
        "# Create comparison DataFrame\n",
        "comparison_data = {\n",
        "    'Model': ['CatBoost (Optimized)', 'Logistic Regression (Optimized)', 'LightGBM (Optimized)', 'TabPFN (Optimized)'],\n",
        "    'Test Accuracy': [\n",
        "        catboost_cv_results['test_accuracy'].mean(),\n",
        "        lr_cv_results['test_accuracy'].mean(),\n",
        "        lgbm_cv_results['test_accuracy'].mean(),\n",
        "        tabpfn_cv_results['test_accuracy'].mean()\n",
        "    ],\n",
        "    'Test Precision': [\n",
        "        catboost_cv_results['test_precision'].mean(),\n",
        "        lr_cv_results['test_precision'].mean(),\n",
        "        lgbm_cv_results['test_precision'].mean(),\n",
        "        tabpfn_cv_results['test_precision'].mean()\n",
        "    ],\n",
        "    'Test Recall': [\n",
        "        catboost_cv_results['test_recall'].mean(),\n",
        "        lr_cv_results['test_recall'].mean(),\n",
        "        lgbm_cv_results['test_recall'].mean(),\n",
        "        tabpfn_cv_results['test_recall'].mean()\n",
        "    ],\n",
        "    'Test F1': [\n",
        "        catboost_cv_results['test_f1'].mean(),\n",
        "        lr_cv_results['test_f1'].mean(),\n",
        "        lgbm_cv_results['test_f1'].mean(),\n",
        "        tabpfn_cv_results['test_f1'].mean()\n",
        "    ],\n",
        "    'Test F2': [\n",
        "        catboost_cv_results['test_f2'].mean(),\n",
        "        lr_cv_results['test_f2'].mean(),\n",
        "        lgbm_cv_results['test_f2'].mean(),\n",
        "        tabpfn_cv_results['test_f2'].mean()\n",
        "    ],\n",
        "    'Test ROC-AUC': [\n",
        "        catboost_cv_results['test_roc_auc'].mean(),\n",
        "        lr_cv_results['test_roc_auc'].mean(),\n",
        "        lgbm_cv_results['test_roc_auc'].mean(),\n",
        "        tabpfn_cv_results['test_roc_auc'].mean()\n",
        "    ],\n",
        "    'False Negative Rate (%)': [catboost_fn_rate, lr_fn_rate, lgbm_fn_rate, tabpfn_cv_results['false_negative_rate'].mean()],\n",
        "    'Train/Test Gap (Accuracy)': [\n",
        "        catboost_cv_results['train_accuracy'].mean() - catboost_cv_results['test_accuracy'].mean(),\n",
        "        lr_cv_results['train_accuracy'].mean() - lr_cv_results['test_accuracy'].mean(),\n",
        "        lgbm_cv_results['train_accuracy'].mean() - lgbm_cv_results['test_accuracy'].mean(),\n",
        "        tabpfn_cv_results['train_accuracy'].mean() - tabpfn_cv_results['test_accuracy'].mean()\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.round(4)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON OF OPTIMIZED MODELS\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Sort by F2 score (primary metric)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODELS RANKED BY TEST F2 SCORE (Primary Metric)\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.sort_values('Test F2', ascending=False).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Best Parameters and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Parameters Summary:\n",
            "\n",
            "CATBOOST:\n",
            "  Best F2 Score: 0.7477\n",
            "  Best Parameters:\n",
            "    subsample: 0.8\n",
            "    random_strength: 0.5\n",
            "    min_data_in_leaf: 3\n",
            "    learning_rate: 0.05\n",
            "    l2_leaf_reg: 3\n",
            "    iterations: 100\n",
            "    depth: 4\n",
            "\n",
            "LOGISTIC REGRESSION:\n",
            "  Best F2 Score: 0.7215\n",
            "  Best Parameters:\n",
            "    solver: saga\n",
            "    penalty: l1\n",
            "    max_iter: 1000\n",
            "    class_weight: balanced\n",
            "    C: 0.1\n",
            "\n",
            "LIGHTGBM:\n",
            "  Best F2 Score: 0.7609\n",
            "  Best Parameters:\n",
            "    subsample: 0.7\n",
            "    reg_lambda: 0.1\n",
            "    reg_alpha: 0.5\n",
            "    num_leaves: 15\n",
            "    n_estimators: 400\n",
            "    min_child_samples: 20\n",
            "    max_depth: 4\n",
            "    learning_rate: 0.01\n",
            "    colsample_bytree: 0.9\n",
            "\n",
            "TABPFN:\n",
            "  Best F2 Score: 0.7733\n",
            "  Best Parameters:\n",
            "    threshold: 0.10242949426174164\n"
          ]
        }
      ],
      "source": [
        "# Save best parameters to JSON\n",
        "best_params = {\n",
        "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    'catboost': {\n",
        "        'best_params': catboost_search.best_params_,\n",
        "        'best_f2_score': float(catboost_search.best_score_),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(catboost_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(catboost_cv_results['test_precision'].mean()),\n",
        "            'recall': float(catboost_cv_results['test_recall'].mean()),\n",
        "            'f1': float(catboost_cv_results['test_f1'].mean()),\n",
        "            'f2': float(catboost_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(catboost_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(catboost_fn_rate)\n",
        "        }\n",
        "    },\n",
        "    'logistic_regression': {\n",
        "        'best_params': {k.replace('classifier__', ''): v for k, v in lr_search.best_params_.items()},\n",
        "        'best_f2_score': float(lr_search.best_score_),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(lr_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(lr_cv_results['test_precision'].mean()),\n",
        "            'recall': float(lr_cv_results['test_recall'].mean()),\n",
        "            'f1': float(lr_cv_results['test_f1'].mean()),\n",
        "            'f2': float(lr_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(lr_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(lr_fn_rate)\n",
        "        }\n",
        "    },\n",
        "    'lightgbm': {\n",
        "        'best_params': lgbm_search.best_params_,\n",
        "        'best_f2_score': float(lgbm_search.best_score_),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(lgbm_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(lgbm_cv_results['test_precision'].mean()),\n",
        "            'recall': float(lgbm_cv_results['test_recall'].mean()),\n",
        "            'f1': float(lgbm_cv_results['test_f1'].mean()),\n",
        "            'f2': float(lgbm_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(lgbm_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(lgbm_fn_rate)\n",
        "        }\n",
        "    },\n",
        "    'tabpfn': {\n",
        "        'best_params': tab_pfn_best_params_,\n",
        "        'best_f2_score': float(tabpfn_cv_results['test_f2'].mean()),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(tabpfn_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(tabpfn_cv_results['test_precision'].mean()),\n",
        "            'recall': float(tabpfn_cv_results['test_recall'].mean()),\n",
        "            'f1': float(tabpfn_cv_results['test_f1'].mean()),\n",
        "            'f2': float(tabpfn_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(tabpfn_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(tabpfn_cv_results['false_negative_rate'].mean())\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "results_dir = Path(\"../models\")\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "params_file = results_dir / \"best_hyperparameters.json\"\n",
        "\n",
        "with open(params_file, 'w') as f:\n",
        "    json.dump(best_params, f, indent=4)\n",
        "\n",
        "print(\"\\nBest Parameters Summary:\")\n",
        "for model_name, model_data in best_params.items():\n",
        "    if model_name != 'timestamp':\n",
        "        print(f\"\\n{model_name.upper().replace('_', ' ')}:\")\n",
        "        print(f\"  Best F2 Score: {model_data['best_f2_score']:.4f}\")\n",
        "        print(f\"  Best Parameters:\")\n",
        "        for param, value in model_data['best_params'].items():\n",
        "            print(f\"    {param}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardao\\AppData\\Local\\Temp\\ipykernel_15336\\109708918.py:28: RuntimeWarning: Mean of empty slice.\n",
            "  'train_precision': cv_results['train_precision'].mean(),\n",
            "c:\\Users\\ardao\\anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "C:\\Users\\ardao\\AppData\\Local\\Temp\\ipykernel_15336\\109708918.py:29: RuntimeWarning: Mean of empty slice.\n",
            "  'train_recall': cv_results['train_recall'].mean(),\n",
            "C:\\Users\\ardao\\AppData\\Local\\Temp\\ipykernel_15336\\109708918.py:30: RuntimeWarning: Mean of empty slice.\n",
            "  'train_f1': cv_results['train_f1'].mean(),\n",
            "C:\\Users\\ardao\\AppData\\Local\\Temp\\ipykernel_15336\\109708918.py:31: RuntimeWarning: Mean of empty slice.\n",
            "  'train_f2': cv_results['train_f2'].mean(),\n",
            "C:\\Users\\ardao\\AppData\\Local\\Temp\\ipykernel_15336\\109708918.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  all_results = pd.concat([existing_results, optimized_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "# Save optimized results to CSV (append to existing model_results.csv)\n",
        "results_csv = results_dir / \"model_results.csv\"\n",
        "\n",
        "# Prepare results for CSV\n",
        "optimized_results = []\n",
        "\n",
        "for model_name, model_data, cv_results, fn_rate in [\n",
        "    ('CatBoost (Optimized)', 'CatBoost', catboost_cv_results, catboost_fn_rate),\n",
        "    ('Logistic Regression (Optimized)', 'Logistic Regression', lr_cv_results, lr_fn_rate),\n",
        "    ('LightGBM (Optimized)', 'LightGBM', lgbm_cv_results, lgbm_fn_rate),\n",
        "    ('TabPFN (Optimized)', 'TabPFN', tabpfn_cv_results, tabpfn_cv_results['false_negative_rate'])\n",
        "]:\n",
        "    result = {\n",
        "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'model': model_name,\n",
        "        'cv_splits': n_splits,\n",
        "        'scaler': 'StandardScaler' if 'Logistic' in model_name else 'PowerTransformer+StandardScaler',\n",
        "        'class_weight': f\"class_weights=[1, {class_weight_ratio:.2f}]\" if 'CatBoost' in model_name else (\n",
        "            'balanced' if 'Logistic' in model_name else f\"scale_pos_weight={class_weight_ratio:.2f}\"\n",
        "        ),\n",
        "        'test_accuracy': cv_results['test_accuracy'].mean(),\n",
        "        'test_precision': cv_results['test_precision'].mean(),\n",
        "        'test_recall': cv_results['test_recall'].mean(),\n",
        "        'test_f1': cv_results['test_f1'].mean(),\n",
        "        'test_f2': cv_results['test_f2'].mean(),\n",
        "        'test_roc_auc': cv_results['test_roc_auc'].mean(),\n",
        "        'train_accuracy': cv_results['train_accuracy'].mean(),\n",
        "        'train_precision': cv_results['train_precision'].mean(),\n",
        "        'train_recall': cv_results['train_recall'].mean(),\n",
        "        'train_f1': cv_results['train_f1'].mean(),\n",
        "        'train_f2': cv_results['train_f2'].mean(),\n",
        "        'train_roc_auc': cv_results['train_roc_auc'].mean(),\n",
        "        'train_test_gap_accuracy': cv_results['train_accuracy'].mean() - cv_results['test_accuracy'].mean(),\n",
        "        'false_negative_rate': fn_rate,\n",
        "        'false_negative_percentage': (fn_rate / 100) * (y == 1).sum() / len(y) * 100,\n",
        "        'notes': f\"Optimized hyperparameters - see best_hyperparameters.json\"\n",
        "    }\n",
        "    optimized_results.append(result)\n",
        "\n",
        "# Append to existing CSV\n",
        "optimized_df = pd.DataFrame(optimized_results)\n",
        "if results_csv.exists():\n",
        "    existing_results = pd.read_csv(results_csv)\n",
        "    all_results = pd.concat([existing_results, optimized_df], ignore_index=True)\n",
        "    all_results.to_csv(results_csv, index=False)\n",
        "else:\n",
        "    optimized_df.to_csv(results_csv, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Hyperparameter optimization has been completed for the top 4 models based on F2 score. Results are ranked by optimized F2 score:\n",
        "\n",
        "### Optimization Results (Ranked by F2 Score):\n",
        "1. **TabPFN (Optimized)** - **BEST PERFORMER** \n",
        "   - **Test F2 Score**: 0.7733 (↑ from 0.7685 baseline, +0.6% improvement)\n",
        "   - **Test Accuracy**: 0.7286 (↑ from 0.7029 baseline)\n",
        "   - **Test Recall**: 0.9484 (↓ from 0.9506 baseline, -0.2% slight decrease) - **HIGHEST**\n",
        "   - **Test Precision**: 0.4464 (↑ from 0.4350 baseline)\n",
        "   - **Test ROC-AUC**: 0.9034 (↓ from 0.9170 baseline)\n",
        "   - **False Negative Rate**: 5.16% (↑ from 4.94% baseline) - **LOWEST**\n",
        "   - **Train/Test Gap**: 0.0318 (3.18%) - Low overfitting\n",
        "   - **Key Hyperparameters**: threshold=0.1021\n",
        "\n",
        "2. **LightGBM (Optimized)**\n",
        "   - **Test F2 Score**: 0.7609 (↑ from 0.6859 baseline, +10.9% improvement)\n",
        "   - **Test Accuracy**: 0.8300 (↑ from 0.8357 baseline)\n",
        "   - **Test Recall**: 0.8245 (↑ from 0.7080 baseline, +16.5% improvement)\n",
        "   - **Test Precision**: 0.5828\n",
        "   - **Test ROC-AUC**: 0.8280 (↑ from 0.7899 baseline)\n",
        "   - **False Negative Rate**: 17.53% (↓ from 29.22% baseline, -40% reduction) - **LOWEST**\n",
        "   - **Train/Test Gap**: 0.0514 (5.14%) - Moderate overfitting\n",
        "   - **Key Hyperparameters**: learning_rate=0.01, n_estimators=400, max_depth=4, num_leaves=15\n",
        "\n",
        "3. **CatBoost (Optimized)**\n",
        "   - **Test F2 Score**: 0.7477 (↑ from 0.7152 baseline, +4.5% improvement)\n",
        "   - **Test Accuracy**: 0.8300 (↑ from 0.8186 baseline)\n",
        "   - **Test Recall**: 0.8054 (↑ from 0.7662 baseline, +5.1% improvement)\n",
        "   - **Test Precision**: 0.5839\n",
        "   - **Test ROC-AUC**: 0.8212 (↓ from 0.8999 baseline)\n",
        "   - **False Negative Rate**: 19.48% (↓ from 23.38% baseline, -16.7% reduction)\n",
        "   - **Train/Test Gap**: 0.0293 (2.93%) - Minimal overfitting\n",
        "   - **Key Hyperparameters**: learning_rate=0.05, iterations=100, depth=4, subsample=0.8\n",
        "\n",
        "4. **Logistic Regression (Optimized)**\n",
        "   - **Test F2 Score**: 0.7215 (↑ from 0.7129 baseline, +1.2% improvement)\n",
        "   - **Test Accuracy**: 0.7729 (↓ from 0.7800 baseline)\n",
        "   - **Test Recall**: 0.8187 (↑ from 0.7987 baseline, +2.5% improvement)\n",
        "   - **Test Precision**: 0.4933\n",
        "   - **Test ROC-AUC**: 0.7894 (↑ from 0.7867 baseline)\n",
        "   - **False Negative Rate**: 18.18% (↓ from 20.13% baseline, -9.7% reduction)\n",
        "   - **Train/Test Gap**: 0.0039 (0.39%) - **NO OVERFITTING** - Best generalization\n",
        "   - **Key Hyperparameters**: C=0.1, penalty='l1', solver='saga', class_weight='balanced'\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "- **TabPFN achieved the best F2 score (0.7733)** and lowest false negative rate (5.16%), making it the safest model for tsunami detection.\n",
        "- **LightGBM** followed as the second-best performer (F2: 0.7609), offering higher accuracy but lower recall than TabPFN.\n",
        "- All optimized models showed **improved F2 scores** compared to baseline models.\n",
        "- **False negative rates decreased** significantly, with TabPFN achieving a remarkable 5.16% (critical for safety).\n",
        "- **Logistic Regression** shows the best generalization with minimal train/test gap (0.39%).\n",
        "- All models were optimized using **F2 score** as the primary metric (emphasizes recall).\n",
        "\n",
        "### Model Comparison:\n",
        "\n",
        "| Metric | TabPFN (Opt) | LightGBM (Opt) | CatBoost (Opt) | Logistic Reg (Opt) | Winner |\n",
        "|--------|--------------|----------------|----------------|-------------------|--------|\n",
        "| **F2 Score** | 0.7733 | 0.7609 | 0.7477 | 0.7215 | **TabPFN** |\n",
        "| **Recall** | 0.9484 | 0.8245 | 0.8054 | 0.8187 | **TabPFN** |\n",
        "| **False Negative Rate** | 5.16% | 17.53% | 19.48% | 18.18% | **TabPFN** |\n",
        "| **Accuracy** | 0.7286 | 0.8300 | 0.8300 | 0.7729 | **LightGBM/CatBoost** |\n",
        "| **ROC-AUC** | 0.9034 | 0.8280 | 0.8212 | 0.7894 | **TabPFN** |\n",
        "| **Generalization** | 3.18% gap | 5.14% gap | 2.93% gap | 0.39% gap | **Logistic Reg** |\n",
        "\n",
        "### Recommendations:\n",
        "\n",
        "1. **For Maximum Safety (Primary Goal)**: **TabPFN (Optimized)** - Best overall performance with highest F2 score and lowest false negative rate. In a tsunami warning system, missing a positive case (False Negative) is the most critical error, making TabPFN the superior choice despite lower overall accuracy.\n",
        "2. **For Production Efficiency**: **LightGBM (Optimized)** - If computational resources are limited or inference speed is paramount, LightGBM offers a strong alternative.\n",
        "3. **For Interpretability**: **Logistic Regression (Optimized)** - Best generalization and interpretable coefficients.\n",
        "\n",
        "### Next Steps:\n",
        "- Deploy **TabPFN (Optimized)** as the primary model for tsunami detection.\n",
        "- Consider ensemble methods combining TabPFN (for recall) and LightGBM (for precision/accuracy) for improved robustness.\n",
        "- Monitor false negative rate in production to ensure safety standards are met.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
