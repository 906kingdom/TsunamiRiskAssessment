{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Optimization for Top Models\n",
        "\n",
        "Based on baseline test F2 scores from model_results.csv, we selected the top models for hyperparameter optimization:\n",
        "1. **CatBoost**: 0.7152 (F2 score)\n",
        "2. **Logistic Regression**: 0.7129 (F2 score)\n",
        "3. **LightGBM**: 0.6859 (F2 score)\n",
        "4. **Neural Network (MLP)**: 0.7366 (F2 score)\n",
        "\n",
        "This notebook performs hyperparameter optimization for these models using F2 score as the primary metric (emphasizes recall - critical for tsunami detection).\n",
        "\n",
        "**Note**: After optimization, results are ranked by F2 score. See the Summary section for detailed results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_validate, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import (\n",
        "    make_scorer, accuracy_score, precision_score, recall_score, \n",
        "    f1_score, fbeta_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "data_path = Path(\"../data/processed/earthquake_data_tsunami_scaled.csv\")\n",
        "data_df = pd.read_csv(data_path)\n",
        "\n",
        "# Prepare features (same as in previous notebooks)\n",
        "features_to_exclude = ['tsunami', 'Year', 'Month','month_number','dmin','nst','longitude','latitude']\n",
        "X = data_df.drop(columns=[col for col in features_to_exclude if col in data_df.columns])\n",
        "y = data_df['tsunami']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MLP Model Definition (from 04_G_NeuralNetwork.ipynb)\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Layer Perceptron for binary classification.\n",
        "    Architecture: input_dim -> hidden_dim -> hidden_dim//2 -> 1 (logits)\n",
        "    Uses BCEWithLogitsLoss, so output is logits (sigmoid applied in loss function).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=64, dropout_rate=0.5):\n",
        "        super(MLP, self).__init__()\n",
        "        # First hidden layer\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # Dropout for regularization (prevents overfitting)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        # Second hidden layer (reduces dimensionality)\n",
        "        self.layer2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # Output layer (single neuron for binary classification)\n",
        "        self.output = nn.Linear(hidden_dim // 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout(x)  # Applied during training, disabled during eval\n",
        "        x = self.layer2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.output(x)  # Returns logits (not probabilities)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Sklearn-compatible wrapper for PyTorch MLP\n",
        "class MLPClassifier(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"\n",
        "    Sklearn-compatible wrapper for PyTorch MLP model.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim=64, dropout_rate=0.5, learning_rate=0.001, \n",
        "                 batch_size=32, epochs=100, patience=10, pos_weight=None, random_state=42):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.patience = patience\n",
        "        self.pos_weight = pos_weight\n",
        "        self.random_state = random_state\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.input_dim = None\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        # Set random seeds for reproducibility\n",
        "        torch.manual_seed(self.random_state)\n",
        "        np.random.seed(self.random_state)\n",
        "        \n",
        "        # Store input dimension\n",
        "        self.input_dim = X.shape[1]\n",
        "        \n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        \n",
        "        # Convert to PyTorch tensors\n",
        "        X_tensor = torch.FloatTensor(X_scaled)\n",
        "        y_tensor = torch.FloatTensor(y.values if hasattr(y, 'values') else y).unsqueeze(1)\n",
        "        \n",
        "        # Split into train and validation for early stopping\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_tensor, y_tensor, test_size=0.2, random_state=self.random_state, \n",
        "            stratify=y if hasattr(y, 'values') else y\n",
        "        )\n",
        "        \n",
        "        # Create data loader\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        \n",
        "        # Initialize model\n",
        "        self.model = MLP(input_dim=self.input_dim, hidden_dim=self.hidden_dim, \n",
        "                        dropout_rate=self.dropout_rate)\n",
        "        \n",
        "        # Setup loss and optimizer\n",
        "        if self.pos_weight is not None:\n",
        "            pos_weight_tensor = torch.tensor(self.pos_weight, dtype=torch.float32)\n",
        "        else:\n",
        "            pos_weight_tensor = torch.tensor(1.0, dtype=torch.float32)\n",
        "        \n",
        "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        \n",
        "        # Early stopping setup\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "        best_model_state = None\n",
        "        \n",
        "        # Training loop\n",
        "        for epoch in range(self.epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            for inputs, targets in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(X_val)\n",
        "                val_loss = criterion(val_outputs, y_val).item()\n",
        "            \n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                best_model_state = self.model.state_dict().copy()\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= self.patience:\n",
        "                    break\n",
        "        \n",
        "        # Load best model\n",
        "        if best_model_state is not None:\n",
        "            self.model.load_state_dict(best_model_state)\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Return probability predictions\"\"\"\n",
        "        self.model.eval()\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        X_tensor = torch.FloatTensor(X_scaled)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = self.model(X_tensor)\n",
        "            proba = torch.sigmoid(logits).numpy().flatten()\n",
        "        \n",
        "        # Return in sklearn format: [prob_class_0, prob_class_1]\n",
        "        return np.column_stack([1 - proba, proba])\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Return binary predictions\"\"\"\n",
        "        proba = self.predict_proba(X)[:, 1]\n",
        "        return (proba > 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.5454545454545454"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# F2 scorer (emphasizes recall - critical for tsunami detection)\n",
        "f2_scorer = make_scorer(fbeta_score, beta=2.0, zero_division=0)\n",
        "\n",
        "# Calculate class weight ratio\n",
        "class_weight_ratio = (y == 0).sum() / (y == 1).sum()\n",
        "float(class_weight_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: CatBoost Hyperparameter Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost parameter grid:\n",
            "  depth: [3, 4, 5, 6]\n",
            "  learning_rate: [0.01, 0.05, 0.1, 0.15]\n",
            "  iterations: [100, 200, 300]\n",
            "  l2_leaf_reg: [1, 3, 5, 7]\n",
            "  subsample: [0.6, 0.7, 0.8, 0.9]\n",
            "  min_data_in_leaf: [1, 3, 5, 10]\n",
            "  random_strength: [0.5, 1.0, 2.0]\n"
          ]
        }
      ],
      "source": [
        "# CatBoost parameter grid\n",
        "catboost_param_grid = {\n",
        "    'depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
        "    'iterations': [100, 200, 300],\n",
        "    'l2_leaf_reg': [1, 3, 5, 7],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
        "    'min_data_in_leaf': [1, 3, 5, 10],\n",
        "    'random_strength': [0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "print(\"CatBoost parameter grid:\")\n",
        "for key, value in catboost_param_grid.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "CatBoost Best Parameters:\n",
            "{'subsample': 0.8, 'random_strength': 0.5, 'min_data_in_leaf': 3, 'learning_rate': 0.05, 'l2_leaf_reg': 3, 'iterations': 100, 'depth': 4}\n",
            "\n",
            "CatBoost Best F2 Score: 0.7477\n"
          ]
        }
      ],
      "source": [
        "# CatBoost base model\n",
        "catboost_base = CatBoostClassifier(\n",
        "    class_weights=[1, class_weight_ratio],\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=False,\n",
        "    allow_writing_files=False,\n",
        "    loss_function='Logloss'\n",
        ")\n",
        "\n",
        "# Randomized search (faster than grid search for large parameter spaces)\n",
        "catboost_search = RandomizedSearchCV(\n",
        "    estimator=catboost_base,\n",
        "    param_distributions=catboost_param_grid,\n",
        "    n_iter=50,  # Number of parameter settings sampled\n",
        "    cv=skf,\n",
        "    scoring=f2_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "catboost_search.fit(X, y)\n",
        "\n",
        "print(\"\\nCatBoost Best Parameters:\")\n",
        "print(catboost_search.best_params_)\n",
        "print(f\"\\nCatBoost Best F2 Score: {catboost_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost Optimized Results:\n",
            "  Test Accuracy: 0.8300\n",
            "  Test Precision: 0.5839\n",
            "  Test Recall: 0.8054\n",
            "  Test F1: 0.6760\n",
            "  Test F2: 0.7477\n",
            "  Test ROC-AUC: 0.8212\n",
            "  False Negative Rate: 19.48%\n",
            "  Train/Test Gap (Accuracy): 0.0293\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best CatBoost model with full metrics\n",
        "scoring_dict = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, zero_division=0),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'f2': f2_scorer,\n",
        "    'roc_auc': make_scorer(roc_auc_score)\n",
        "}\n",
        "\n",
        "catboost_best = catboost_search.best_estimator_\n",
        "catboost_cv_results = cross_validate(\n",
        "    catboost_best, X, y,\n",
        "    cv=skf,\n",
        "    scoring=scoring_dict,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "catboost_y_pred = cross_val_predict(catboost_best, X, y, cv=skf, n_jobs=-1)\n",
        "catboost_cm = confusion_matrix(y, catboost_y_pred)\n",
        "catboost_fn_rate = catboost_cm[1, 0] / catboost_cm[1, :].sum() * 100\n",
        "\n",
        "print(\"CatBoost Optimized Results:\")\n",
        "print(f\"  Test Accuracy: {catboost_cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Test Precision: {catboost_cv_results['test_precision'].mean():.4f}\")\n",
        "print(f\"  Test Recall: {catboost_cv_results['test_recall'].mean():.4f}\")\n",
        "print(f\"  Test F1: {catboost_cv_results['test_f1'].mean():.4f}\")\n",
        "print(f\"  Test F2: {catboost_cv_results['test_f2'].mean():.4f}\")\n",
        "print(f\"  Test ROC-AUC: {catboost_cv_results['test_roc_auc'].mean():.4f}\")\n",
        "print(f\"  False Negative Rate: {catboost_fn_rate:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {catboost_cv_results['train_accuracy'].mean() - catboost_cv_results['test_accuracy'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Logistic Regression Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression parameter grid:\n",
            "  classifier__C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
            "  classifier__penalty: ['l1', 'l2', 'elasticnet']\n",
            "  classifier__solver: ['lbfgs', 'liblinear', 'saga']\n",
            "  classifier__max_iter: [1000, 2000, 5000]\n",
            "  classifier__class_weight: ['balanced', {0: 1, 1: np.float64(3.5454545454545454)}, None]\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression parameter grid\n",
        "lr_param_grid = {\n",
        "    'classifier__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'classifier__solver': ['lbfgs', 'liblinear', 'saga'],\n",
        "    'classifier__max_iter': [1000, 2000, 5000],\n",
        "    'classifier__class_weight': ['balanced', {0: 1, 1: class_weight_ratio}, None]\n",
        "}\n",
        "\n",
        "print(\"Logistic Regression parameter grid:\")\n",
        "for key, value in lr_param_grid.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "Logistic Regression Best Parameters:\n",
            "{'classifier__solver': 'saga', 'classifier__penalty': 'l1', 'classifier__max_iter': 1000, 'classifier__class_weight': 'balanced', 'classifier__C': 0.1}\n",
            "\n",
            "Logistic Regression Best F2 Score: 0.7215\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression pipeline with StandardScaler\n",
        "lr_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "\n",
        "lr_search = RandomizedSearchCV(\n",
        "    estimator=lr_pipeline,\n",
        "    param_distributions={\n",
        "        'classifier__C': lr_param_grid['classifier__C'],\n",
        "        'classifier__penalty': ['l1', 'l2'],  # Exclude elasticnet for simplicity\n",
        "        'classifier__solver': ['liblinear', 'saga'],  # Both support l1 and l2\n",
        "        'classifier__max_iter': lr_param_grid['classifier__max_iter'],\n",
        "        'classifier__class_weight': lr_param_grid['classifier__class_weight']\n",
        "    },\n",
        "    n_iter=50,  # Sample 50 parameter combinations\n",
        "    cv=skf,\n",
        "    scoring=f2_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1,\n",
        "    error_score='raise'\n",
        ")\n",
        "\n",
        "lr_search.fit(X, y)\n",
        "\n",
        "print(\"\\nLogistic Regression Best Parameters:\")\n",
        "print(lr_search.best_params_)\n",
        "print(f\"\\nLogistic Regression Best F2 Score: {lr_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Optimized Results:\n",
            "  Test Accuracy: 0.7729\n",
            "  Test Precision: 0.4933\n",
            "  Test Recall: 0.8187\n",
            "  Test F1: 0.6139\n",
            "  Test F2: 0.7215\n",
            "  Test ROC-AUC: 0.7894\n",
            "  False Negative Rate: 18.18%\n",
            "  Train/Test Gap (Accuracy): 0.0039\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best Logistic Regression model\n",
        "lr_best = lr_search.best_estimator_\n",
        "lr_cv_results = cross_validate(\n",
        "    lr_best, X, y,\n",
        "    cv=skf,\n",
        "    scoring=scoring_dict,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_y_pred = cross_val_predict(lr_best, X, y, cv=skf, n_jobs=-1)\n",
        "lr_cm = confusion_matrix(y, lr_y_pred)\n",
        "lr_fn_rate = lr_cm[1, 0] / lr_cm[1, :].sum() * 100\n",
        "\n",
        "print(\"Logistic Regression Optimized Results:\")\n",
        "print(f\"  Test Accuracy: {lr_cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Test Precision: {lr_cv_results['test_precision'].mean():.4f}\")\n",
        "print(f\"  Test Recall: {lr_cv_results['test_recall'].mean():.4f}\")\n",
        "print(f\"  Test F1: {lr_cv_results['test_f1'].mean():.4f}\")\n",
        "print(f\"  Test F2: {lr_cv_results['test_f2'].mean():.4f}\")\n",
        "print(f\"  Test ROC-AUC: {lr_cv_results['test_roc_auc'].mean():.4f}\")\n",
        "print(f\"  False Negative Rate: {lr_fn_rate:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {lr_cv_results['train_accuracy'].mean() - lr_cv_results['test_accuracy'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 3: LightGBM Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM parameter grid:\n",
            "  max_depth: [3, 4, 5, 6, 7]\n",
            "  learning_rate: [0.01, 0.05, 0.1, 0.15]\n",
            "  n_estimators: [100, 200, 300, 400]\n",
            "  num_leaves: [15, 31, 50, 70]\n",
            "  subsample: [0.6, 0.7, 0.8, 0.9]\n",
            "  colsample_bytree: [0.6, 0.7, 0.8, 0.9]\n",
            "  min_child_samples: [5, 10, 20, 30]\n",
            "  reg_alpha: [0, 0.1, 0.5, 1.0]\n",
            "  reg_lambda: [0, 0.1, 0.5, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# LightGBM parameter grid\n",
        "lgbm_param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'num_leaves': [15, 31, 50, 70],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
        "    'min_child_samples': [5, 10, 20, 30],\n",
        "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
        "    'reg_lambda': [0, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "print(\"LightGBM parameter grid:\")\n",
        "for key, value in lgbm_param_grid.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "LightGBM Best Parameters:\n",
            "{'subsample': 0.7, 'reg_lambda': 0.1, 'reg_alpha': 0.5, 'num_leaves': 15, 'n_estimators': 400, 'min_child_samples': 20, 'max_depth': 4, 'learning_rate': 0.01, 'colsample_bytree': 0.9}\n",
            "\n",
            "LightGBM Best F2 Score: 0.7609\n"
          ]
        }
      ],
      "source": [
        "# LightGBM base model\n",
        "lgbm_base = lgb.LGBMClassifier(\n",
        "    scale_pos_weight=class_weight_ratio,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbosity=-1,\n",
        "    force_col_wise=True,\n",
        "    objective='binary',\n",
        "    metric='binary_logloss'\n",
        ")\n",
        "\n",
        "# Randomized search\n",
        "lgbm_search = RandomizedSearchCV(\n",
        "    estimator=lgbm_base,\n",
        "    param_distributions=lgbm_param_grid,\n",
        "    n_iter=50,  # Number of parameter settings sampled\n",
        "    cv=skf,\n",
        "    scoring=f2_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lgbm_search.fit(X, y)\n",
        "\n",
        "print(\"\\nLightGBM Best Parameters:\")\n",
        "print(lgbm_search.best_params_)\n",
        "print(f\"\\nLightGBM Best F2 Score: {lgbm_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM Optimized Results:\n",
            "  Test Accuracy: 0.8300\n",
            "  Test Precision: 0.5828\n",
            "  Test Recall: 0.8245\n",
            "  Test F1: 0.6823\n",
            "  Test F2: 0.7609\n",
            "  Test ROC-AUC: 0.8280\n",
            "  False Negative Rate: 17.53%\n",
            "  Train/Test Gap (Accuracy): 0.0514\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best LightGBM model\n",
        "lgbm_best = lgbm_search.best_estimator_\n",
        "lgbm_cv_results = cross_validate(\n",
        "    lgbm_best, X, y,\n",
        "    cv=skf,\n",
        "    scoring=scoring_dict,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_y_pred = cross_val_predict(lgbm_best, X, y, cv=skf, n_jobs=-1)\n",
        "lgbm_cm = confusion_matrix(y, lgbm_y_pred)\n",
        "lgbm_fn_rate = lgbm_cm[1, 0] / lgbm_cm[1, :].sum() * 100\n",
        "\n",
        "print(\"LightGBM Optimized Results:\")\n",
        "print(f\"  Test Accuracy: {lgbm_cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Test Precision: {lgbm_cv_results['test_precision'].mean():.4f}\")\n",
        "print(f\"  Test Recall: {lgbm_cv_results['test_recall'].mean():.4f}\")\n",
        "print(f\"  Test F1: {lgbm_cv_results['test_f1'].mean():.4f}\")\n",
        "print(f\"  Test F2: {lgbm_cv_results['test_f2'].mean():.4f}\")\n",
        "print(f\"  Test ROC-AUC: {lgbm_cv_results['test_roc_auc'].mean():.4f}\")\n",
        "print(f\"  False Negative Rate: {lgbm_fn_rate:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {lgbm_cv_results['train_accuracy'].mean() - lgbm_cv_results['test_accuracy'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of Optimized Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 4: Neural Network (MLP) Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Network (MLP) parameter grid:\n",
            "  hidden_dim: [32, 64, 128]\n",
            "  dropout_rate: [0.3, 0.4, 0.5, 0.6]\n",
            "  learning_rate: [0.0001, 0.001, 0.01]\n",
            "  batch_size: [16, 32, 64]\n",
            "  epochs: [50, 100, 150]\n",
            "  patience: [5, 10, 15]\n"
          ]
        }
      ],
      "source": [
        "# Neural Network (MLP) parameter grid\n",
        "mlp_param_grid = {\n",
        "    'hidden_dim': [32, 64, 128],\n",
        "    'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "    'learning_rate': [0.0001, 0.001, 0.01],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'epochs': [50, 100, 150],\n",
        "    'patience': [5, 10, 15]\n",
        "}\n",
        "\n",
        "print(\"Neural Network (MLP) parameter grid:\")\n",
        "for key, value in mlp_param_grid.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "Neural Network (MLP) Best Parameters:\n",
            "{'patience': 5, 'learning_rate': 0.01, 'hidden_dim': 32, 'epochs': 50, 'dropout_rate': 0.5, 'batch_size': 16}\n",
            "\n",
            "Neural Network (MLP) Best F2 Score: 0.7413\n"
          ]
        }
      ],
      "source": [
        "# Neural Network base model\n",
        "mlp_base = MLPClassifier(\n",
        "    pos_weight=class_weight_ratio,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Randomized search (reduced n_iter for neural networks due to longer training time)\n",
        "mlp_search = RandomizedSearchCV(\n",
        "    estimator=mlp_base,\n",
        "    param_distributions=mlp_param_grid,\n",
        "    n_iter=30,  # Reduced from 50 due to longer training time for neural networks\n",
        "    cv=skf,\n",
        "    scoring=f2_scorer,\n",
        "    n_jobs=1,  # Neural networks don't benefit from parallelization in this context\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "mlp_search.fit(X, y)\n",
        "\n",
        "print(\"\\nNeural Network (MLP) Best Parameters:\")\n",
        "print(mlp_search.best_params_)\n",
        "print(f\"\\nNeural Network (MLP) Best F2 Score: {mlp_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Network (MLP) Optimized Results:\n",
            "  Test Accuracy: 0.8000\n",
            "  Test Precision: 0.5324\n",
            "  Test Recall: 0.8252\n",
            "  Test F1: 0.6449\n",
            "  Test F2: 0.7413\n",
            "  Test ROC-AUC: 0.8091\n",
            "  False Negative Rate: 17.53%\n",
            "  Train/Test Gap (Accuracy): 0.0100\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best Neural Network model\n",
        "mlp_best = mlp_search.best_estimator_\n",
        "mlp_cv_results = cross_validate(\n",
        "    mlp_best, X, y,\n",
        "    cv=skf,\n",
        "    scoring=scoring_dict,\n",
        "    return_train_score=True,\n",
        "    n_jobs=1  # Neural networks don't benefit from parallelization\n",
        ")\n",
        "\n",
        "mlp_y_pred = cross_val_predict(mlp_best, X, y, cv=skf, n_jobs=1)\n",
        "mlp_cm = confusion_matrix(y, mlp_y_pred)\n",
        "mlp_fn_rate = mlp_cm[1, 0] / mlp_cm[1, :].sum() * 100\n",
        "\n",
        "print(\"Neural Network (MLP) Optimized Results:\")\n",
        "print(f\"  Test Accuracy: {mlp_cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"  Test Precision: {mlp_cv_results['test_precision'].mean():.4f}\")\n",
        "print(f\"  Test Recall: {mlp_cv_results['test_recall'].mean():.4f}\")\n",
        "print(f\"  Test F1: {mlp_cv_results['test_f1'].mean():.4f}\")\n",
        "print(f\"  Test F2: {mlp_cv_results['test_f2'].mean():.4f}\")\n",
        "print(f\"  Test ROC-AUC: {mlp_cv_results['test_roc_auc'].mean():.4f}\")\n",
        "print(f\"  False Negative Rate: {mlp_fn_rate:.2f}%\")\n",
        "print(f\"  Train/Test Gap (Accuracy): {mlp_cv_results['train_accuracy'].mean() - mlp_cv_results['test_accuracy'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPARISON OF OPTIMIZED MODELS\n",
            "================================================================================\n",
            "                           Model  Test Accuracy  Test Precision  Test Recall  Test F1  Test F2  Test ROC-AUC  False Negative Rate (%)  Train/Test Gap (Accuracy)\n",
            "            CatBoost (Optimized)         0.8300          0.5839       0.8054   0.6760   0.7477        0.8212                  19.4805                     0.0293\n",
            " Logistic Regression (Optimized)         0.7729          0.4933       0.8187   0.6139   0.7215        0.7894                  18.1818                     0.0039\n",
            "            LightGBM (Optimized)         0.8300          0.5828       0.8245   0.6823   0.7609        0.8280                  17.5325                     0.0514\n",
            "Neural Network (MLP) (Optimized)         0.8000          0.5324       0.8252   0.6449   0.7413        0.8091                  17.5325                     0.0100\n",
            "\n",
            "================================================================================\n",
            "MODELS RANKED BY TEST F2 SCORE (Primary Metric)\n",
            "================================================================================\n",
            "                           Model  Test Accuracy  Test Precision  Test Recall  Test F1  Test F2  Test ROC-AUC  False Negative Rate (%)  Train/Test Gap (Accuracy)\n",
            "            LightGBM (Optimized)         0.8300          0.5828       0.8245   0.6823   0.7609        0.8280                  17.5325                     0.0514\n",
            "            CatBoost (Optimized)         0.8300          0.5839       0.8054   0.6760   0.7477        0.8212                  19.4805                     0.0293\n",
            "Neural Network (MLP) (Optimized)         0.8000          0.5324       0.8252   0.6449   0.7413        0.8091                  17.5325                     0.0100\n",
            " Logistic Regression (Optimized)         0.7729          0.4933       0.8187   0.6139   0.7215        0.7894                  18.1818                     0.0039\n"
          ]
        }
      ],
      "source": [
        "# Create comparison DataFrame\n",
        "comparison_data = {\n",
        "    'Model': ['CatBoost (Optimized)', 'Logistic Regression (Optimized)', 'LightGBM (Optimized)', 'Neural Network (MLP) (Optimized)'],\n",
        "    'Test Accuracy': [\n",
        "        catboost_cv_results['test_accuracy'].mean(),\n",
        "        lr_cv_results['test_accuracy'].mean(),\n",
        "        lgbm_cv_results['test_accuracy'].mean(),\n",
        "        mlp_cv_results['test_accuracy'].mean()\n",
        "    ],\n",
        "    'Test Precision': [\n",
        "        catboost_cv_results['test_precision'].mean(),\n",
        "        lr_cv_results['test_precision'].mean(),\n",
        "        lgbm_cv_results['test_precision'].mean(),\n",
        "        mlp_cv_results['test_precision'].mean()\n",
        "    ],\n",
        "    'Test Recall': [\n",
        "        catboost_cv_results['test_recall'].mean(),\n",
        "        lr_cv_results['test_recall'].mean(),\n",
        "        lgbm_cv_results['test_recall'].mean(),\n",
        "        mlp_cv_results['test_recall'].mean()\n",
        "    ],\n",
        "    'Test F1': [\n",
        "        catboost_cv_results['test_f1'].mean(),\n",
        "        lr_cv_results['test_f1'].mean(),\n",
        "        lgbm_cv_results['test_f1'].mean(),\n",
        "        mlp_cv_results['test_f1'].mean()\n",
        "    ],\n",
        "    'Test F2': [\n",
        "        catboost_cv_results['test_f2'].mean(),\n",
        "        lr_cv_results['test_f2'].mean(),\n",
        "        lgbm_cv_results['test_f2'].mean(),\n",
        "        mlp_cv_results['test_f2'].mean()\n",
        "    ],\n",
        "    'Test ROC-AUC': [\n",
        "        catboost_cv_results['test_roc_auc'].mean(),\n",
        "        lr_cv_results['test_roc_auc'].mean(),\n",
        "        lgbm_cv_results['test_roc_auc'].mean(),\n",
        "        mlp_cv_results['test_roc_auc'].mean()\n",
        "    ],\n",
        "    'False Negative Rate (%)': [catboost_fn_rate, lr_fn_rate, lgbm_fn_rate, mlp_fn_rate],\n",
        "    'Train/Test Gap (Accuracy)': [\n",
        "        catboost_cv_results['train_accuracy'].mean() - catboost_cv_results['test_accuracy'].mean(),\n",
        "        lr_cv_results['train_accuracy'].mean() - lr_cv_results['test_accuracy'].mean(),\n",
        "        lgbm_cv_results['train_accuracy'].mean() - lgbm_cv_results['test_accuracy'].mean(),\n",
        "        mlp_cv_results['train_accuracy'].mean() - mlp_cv_results['test_accuracy'].mean()\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.round(4)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON OF OPTIMIZED MODELS\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Sort by F2 score (primary metric)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODELS RANKED BY TEST F2 SCORE (Primary Metric)\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.sort_values('Test F2', ascending=False).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add Neural Network results to best_params (if not already included)\n",
        "if 'neural_network_mlp' not in best_params:\n",
        "    best_params['neural_network_mlp'] = {\n",
        "        'best_params': mlp_search.best_params_,\n",
        "        'best_f2_score': float(mlp_search.best_score_),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(mlp_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(mlp_cv_results['test_precision'].mean()),\n",
        "            'recall': float(mlp_cv_results['test_recall'].mean()),\n",
        "            'f1': float(mlp_cv_results['test_f1'].mean()),\n",
        "            'f2': float(mlp_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(mlp_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(mlp_fn_rate)\n",
        "        }\n",
        "    }\n",
        "    # Re-save JSON file with Neural Network results\n",
        "    with open(params_file, 'w') as f:\n",
        "        json.dump(best_params, f, indent=4)\n",
        "    print(\"Neural Network results added to best_hyperparameters.json\")\n",
        "else:\n",
        "    print(\"Neural Network results already in best_hyperparameters.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Best Parameters and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Parameters Summary:\n",
            "\n",
            "CATBOOST:\n",
            "  Best F2 Score: 0.7477\n",
            "  Best Parameters:\n",
            "    subsample: 0.8\n",
            "    random_strength: 0.5\n",
            "    min_data_in_leaf: 3\n",
            "    learning_rate: 0.05\n",
            "    l2_leaf_reg: 3\n",
            "    iterations: 100\n",
            "    depth: 4\n",
            "\n",
            "LOGISTIC REGRESSION:\n",
            "  Best F2 Score: 0.7215\n",
            "  Best Parameters:\n",
            "    solver: saga\n",
            "    penalty: l1\n",
            "    max_iter: 1000\n",
            "    class_weight: balanced\n",
            "    C: 0.1\n",
            "\n",
            "LIGHTGBM:\n",
            "  Best F2 Score: 0.7609\n",
            "  Best Parameters:\n",
            "    subsample: 0.7\n",
            "    reg_lambda: 0.1\n",
            "    reg_alpha: 0.5\n",
            "    num_leaves: 15\n",
            "    n_estimators: 400\n",
            "    min_child_samples: 20\n",
            "    max_depth: 4\n",
            "    learning_rate: 0.01\n",
            "    colsample_bytree: 0.9\n"
          ]
        }
      ],
      "source": [
        "# Save best parameters to JSON\n",
        "best_params = {\n",
        "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    'catboost': {\n",
        "        'best_params': catboost_search.best_params_,\n",
        "        'best_f2_score': float(catboost_search.best_score_),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(catboost_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(catboost_cv_results['test_precision'].mean()),\n",
        "            'recall': float(catboost_cv_results['test_recall'].mean()),\n",
        "            'f1': float(catboost_cv_results['test_f1'].mean()),\n",
        "            'f2': float(catboost_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(catboost_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(catboost_fn_rate)\n",
        "        }\n",
        "    },\n",
        "    'logistic_regression': {\n",
        "        'best_params': {k.replace('classifier__', ''): v for k, v in lr_search.best_params_.items()},\n",
        "        'best_f2_score': float(lr_search.best_score_),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(lr_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(lr_cv_results['test_precision'].mean()),\n",
        "            'recall': float(lr_cv_results['test_recall'].mean()),\n",
        "            'f1': float(lr_cv_results['test_f1'].mean()),\n",
        "            'f2': float(lr_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(lr_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(lr_fn_rate)\n",
        "        }\n",
        "    },\n",
        "    'lightgbm': {\n",
        "        'best_params': lgbm_search.best_params_,\n",
        "        'best_f2_score': float(lgbm_search.best_score_),\n",
        "        'test_metrics': {\n",
        "            'accuracy': float(lgbm_cv_results['test_accuracy'].mean()),\n",
        "            'precision': float(lgbm_cv_results['test_precision'].mean()),\n",
        "            'recall': float(lgbm_cv_results['test_recall'].mean()),\n",
        "            'f1': float(lgbm_cv_results['test_f1'].mean()),\n",
        "            'f2': float(lgbm_cv_results['test_f2'].mean()),\n",
        "            'roc_auc': float(lgbm_cv_results['test_roc_auc'].mean()),\n",
        "            'false_negative_rate': float(lgbm_fn_rate)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "results_dir = Path(\"../models\")\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "params_file = results_dir / \"best_hyperparameters.json\"\n",
        "\n",
        "with open(params_file, 'w') as f:\n",
        "    json.dump(best_params, f, indent=4)\n",
        "\n",
        "print(\"\\nBest Parameters Summary:\")\n",
        "for model_name, model_data in best_params.items():\n",
        "    if model_name != 'timestamp':\n",
        "        print(f\"\\n{model_name.upper().replace('_', ' ')}:\")\n",
        "        print(f\"  Best F2 Score: {model_data['best_f2_score']:.4f}\")\n",
        "        print(f\"  Best Parameters:\")\n",
        "        for param, value in model_data['best_params'].items():\n",
        "            print(f\"    {param}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save optimized results to CSV (append to existing model_results.csv)\n",
        "results_csv = results_dir / \"model_results.csv\"\n",
        "\n",
        "# Prepare results for CSV\n",
        "optimized_results = []\n",
        "\n",
        "for model_name, model_data, cv_results, fn_rate in [\n",
        "    ('CatBoost (Optimized)', 'CatBoost', catboost_cv_results, catboost_fn_rate),\n",
        "    ('Logistic Regression (Optimized)', 'Logistic Regression', lr_cv_results, lr_fn_rate),\n",
        "    ('LightGBM (Optimized)', 'LightGBM', lgbm_cv_results, lgbm_fn_rate),\n",
        "    ('Neural Network (MLP) (Optimized)', 'Neural Network (MLP)', mlp_cv_results, mlp_fn_rate)\n",
        "]:\n",
        "    result = {\n",
        "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'model': model_name,\n",
        "        'cv_splits': n_splits,\n",
        "        'scaler': 'StandardScaler' if 'Logistic' in model_name or 'Neural Network' in model_name else 'PowerTransformer+StandardScaler',\n",
        "        'class_weight': f\"class_weights=[1, {class_weight_ratio:.2f}]\" if 'CatBoost' in model_name else (\n",
        "            'balanced' if 'Logistic' in model_name else (\n",
        "                f\"pos_weight={class_weight_ratio:.2f}\" if 'Neural Network' in model_name else f\"scale_pos_weight={class_weight_ratio:.2f}\"\n",
        "            )\n",
        "        ),\n",
        "        'test_accuracy': cv_results['test_accuracy'].mean(),\n",
        "        'test_precision': cv_results['test_precision'].mean(),\n",
        "        'test_recall': cv_results['test_recall'].mean(),\n",
        "        'test_f1': cv_results['test_f1'].mean(),\n",
        "        'test_f2': cv_results['test_f2'].mean(),\n",
        "        'test_roc_auc': cv_results['test_roc_auc'].mean(),\n",
        "        'train_accuracy': cv_results['train_accuracy'].mean(),\n",
        "        'train_precision': cv_results['train_precision'].mean(),\n",
        "        'train_recall': cv_results['train_recall'].mean(),\n",
        "        'train_f1': cv_results['train_f1'].mean(),\n",
        "        'train_f2': cv_results['train_f2'].mean(),\n",
        "        'train_roc_auc': cv_results['train_roc_auc'].mean(),\n",
        "        'train_test_gap_accuracy': cv_results['train_accuracy'].mean() - cv_results['test_accuracy'].mean(),\n",
        "        'false_negative_rate': fn_rate,\n",
        "        'false_negative_percentage': (fn_rate / 100) * (y == 1).sum() / len(y) * 100,\n",
        "        'notes': f\"Optimized hyperparameters - see best_hyperparameters.json\"\n",
        "    }\n",
        "    optimized_results.append(result)\n",
        "\n",
        "# Append to existing CSV\n",
        "optimized_df = pd.DataFrame(optimized_results)\n",
        "if results_csv.exists():\n",
        "    existing_results = pd.read_csv(results_csv)\n",
        "    all_results = pd.concat([existing_results, optimized_df], ignore_index=True)\n",
        "    all_results.to_csv(results_csv, index=False)\n",
        "else:\n",
        "    optimized_df.to_csv(results_csv, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Hyperparameter optimization has been completed for the top models based on F2 score. Results are ranked by optimized F2 score:\n",
        "\n",
        "### Optimization Results (Ranked by F2 Score):\n",
        "\n",
        "1. **LightGBM (Optimized)** - **BEST PERFORMER**\n",
        "   - **Test F2 Score**: 0.7609 (↑ from 0.6859 baseline, +10.9% improvement)\n",
        "   - **Test Accuracy**: 0.8300 (↑ from 0.8357 baseline)\n",
        "   - **Test Recall**: 0.8245 (↑ from 0.7080 baseline, +16.5% improvement)\n",
        "   - **Test Precision**: 0.5828\n",
        "   - **Test ROC-AUC**: 0.8280 (↑ from 0.7899 baseline)\n",
        "   - **False Negative Rate**: 17.53% (↓ from 29.22% baseline, -40% reduction) - **LOWEST**\n",
        "   - **Train/Test Gap**: 0.0514 (5.14%) - Moderate overfitting\n",
        "   - **Key Hyperparameters**: learning_rate=0.01, n_estimators=400, max_depth=4, num_leaves=15\n",
        "\n",
        "2. **CatBoost (Optimized)**\n",
        "   - **Test F2 Score**: 0.7477 (↑ from 0.7152 baseline, +4.5% improvement)\n",
        "   - **Test Accuracy**: 0.8300 (↑ from 0.8186 baseline)\n",
        "   - **Test Recall**: 0.8054 (↑ from 0.7662 baseline, +5.1% improvement)\n",
        "   - **Test Precision**: 0.5839\n",
        "   - **Test ROC-AUC**: 0.8212 (↓ from 0.8999 baseline)\n",
        "   - **False Negative Rate**: 19.48% (↓ from 23.38% baseline, -16.7% reduction)\n",
        "   - **Train/Test Gap**: 0.0293 (2.93%) - Minimal overfitting\n",
        "   - **Key Hyperparameters**: learning_rate=0.05, iterations=100, depth=4, subsample=0.8\n",
        "\n",
        "3. **Neural Network (MLP) (Optimized)**\n",
        "   - **Test F2 Score**: 0.7413 (↑ from 0.7366 baseline, +0.6% improvement)\n",
        "   - **Test Accuracy**: 0.8000 (↓ from 0.8114 baseline)\n",
        "   - **Test Recall**: 0.8252 (↑ from 0.8052 baseline, +2.5% improvement)\n",
        "   - **Test Precision**: 0.5324\n",
        "   - **Test ROC-AUC**: 0.8091 (↓ from 0.8817 baseline)\n",
        "   - **False Negative Rate**: 17.53% (same as baseline) - **Tied for LOWEST**\n",
        "   - **Train/Test Gap**: 0.0100 (1.00%) - Excellent generalization\n",
        "   - **Key Hyperparameters**: hidden_dim=32, dropout_rate=0.5, learning_rate=0.01, batch_size=16, epochs=50, patience=5\n",
        "\n",
        "4. **Logistic Regression (Optimized)**\n",
        "   - **Test F2 Score**: 0.7215 (↑ from 0.7129 baseline, +1.2% improvement)\n",
        "   - **Test Accuracy**: 0.7729 (↓ from 0.7800 baseline)\n",
        "   - **Test Recall**: 0.8187 (↑ from 0.7987 baseline, +2.5% improvement)\n",
        "   - **Test Precision**: 0.4933\n",
        "   - **Test ROC-AUC**: 0.7894 (↑ from 0.7867 baseline)\n",
        "   - **False Negative Rate**: 18.18% (↓ from 20.13% baseline, -9.7% reduction)\n",
        "   - **Train/Test Gap**: 0.0039 (0.39%) - **NO OVERFITTING** - Best generalization\n",
        "   - **Key Hyperparameters**: C=0.1, penalty='l1', solver='saga', class_weight='balanced'\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "- **LightGBM achieved the best F2 score (0.7609)** and tied for lowest false negative rate (17.53%)\n",
        "- **Neural Network (MLP)** achieved the second-best recall (0.8252) and tied for lowest false negative rate (17.53%)\n",
        "- All optimized models showed **improved or maintained F2 scores** compared to baseline models\n",
        "- **False negative rates decreased or maintained** for all models, which is critical for tsunami detection\n",
        "- **Logistic Regression** shows the best generalization with minimal train/test gap (0.39%)\n",
        "- **Neural Network (MLP)** shows excellent generalization with only 1.00% train/test gap\n",
        "- All models were optimized using **F2 score** as the primary metric (emphasizes recall - critical for tsunami detection)\n",
        "- 5-fold stratified cross-validation was used to ensure robust evaluation\n",
        "- RandomizedSearchCV was used for efficiency, sampling 30-50 parameter combinations per model (30 for Neural Network due to longer training time)\n",
        "- Best hyperparameters have been saved to `models/best_hyperparameters.json`\n",
        "- Optimized results have been appended to `models/model_results.csv`\n",
        "\n",
        "### Model Comparison:\n",
        "\n",
        "| Metric | LightGBM (Opt) | CatBoost (Opt) | Neural Network (Opt) | Logistic Reg (Opt) | Winner |\n",
        "|--------|----------------|----------------|---------------------|-------------------|--------|\n",
        "| **F2 Score** | 0.7609 | 0.7477 | 0.7413 | 0.7215 | **LightGBM** |\n",
        "| **Recall** | 0.8245 | 0.8054 | 0.8252 | 0.8187 | **Neural Network** |\n",
        "| **False Negative Rate** | 17.53% | 19.48% | 17.53% | 18.18% | **LightGBM/Neural Network** |\n",
        "| **Accuracy** | 0.8300 | 0.8300 | 0.8000 | 0.7729 | **LightGBM/CatBoost** |\n",
        "| **ROC-AUC** | 0.8280 | 0.8212 | 0.8091 | 0.7894 | **LightGBM** |\n",
        "| **Generalization** | 5.14% gap | 2.93% gap | 1.00% gap | 0.39% gap | **Logistic Reg** |\n",
        "\n",
        "### Recommendations:\n",
        "\n",
        "1. **For Production Deployment**: **LightGBM (Optimized)** - Best overall performance with highest F2 score (0.7609) and tied for lowest false negative rate (17.53%)\n",
        "2. **For High Recall Requirements**: **Neural Network (MLP) (Optimized)** - Highest recall (0.8252) and tied for lowest false negative rate (17.53%) with excellent generalization (1.00% gap)\n",
        "3. **For Interpretability**: **Logistic Regression (Optimized)** - Best generalization (0.39% gap) and interpretable coefficients\n",
        "4. **For Balanced Performance**: **CatBoost (Optimized)** - Good balance between performance and overfitting control\n",
        "\n",
        "### Next Steps:\n",
        "- Deploy **LightGBM (Optimized)** as the primary model for tsunami detection\n",
        "- Consider **Neural Network (MLP) (Optimized)** as an alternative for scenarios requiring maximum recall\n",
        "- Consider ensemble methods combining LightGBM, Neural Network, and CatBoost for improved robustness\n",
        "- Monitor false negative rate in production to ensure safety standards are met (target: <20%)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
